{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TRANSFORMERS_CACHE=/bigstor/zsarwar/models/cache\n",
      "env: CUDA_VISIBLE_DEVICES=3\n"
     ]
    }
   ],
   "source": [
    "%set_env TRANSFORMERS_CACHE=/bigstor/zsarwar/models/cache\n",
    "\n",
    "%set_env CUDA_VISIBLE_DEVICES=3\n",
    "#%set_env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zsarwar/.conda/envs/nlp2/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelWithLMHead, AutoModelForMaskedLM\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from tqdm import tqdm\n",
    "from nltk import tokenize\n",
    "import utils_v4\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import nltk\n",
    "\n",
    "NER = spacy.load(\"en_core_web_sm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--train', type=Path, default='/home/zsarwar/NLP/autoprompt/data/correctly_classified_roberta_large_autoprompt_format_shorter.jsonl', help='Train data path')\n",
    "parser.add_argument('--dev', type=Path, default='/home/zsarwar/NLP/autoprompt/data/correctly_classified_roberta_large_autoprompt_format_shorter.jsonl',help='Dev data path')\n",
    "parser.add_argument('--template', type=str,default='<s> {Pre_Mask}[P]{Post_Mask}[T][T][T][T][T]</s>', help='Template string')\n",
    "parser.add_argument('--label-map', type=str, default=None, help='JSON object defining label map')\n",
    "\n",
    "# LAMA-specific\n",
    "parser.add_argument('--tokenize-labels', action='store_true',\n",
    "                    help='If specified labels are split into word pieces.'\n",
    "                            'Needed for LAMA probe experiments.')\n",
    "parser.add_argument('--filter', action='store_true', default=True,\n",
    "                    help='If specified, filter out special tokens and gold objects.'\n",
    "                            'Furthermore, tokens starting with capital '\n",
    "                            'letters will not appear in triggers. Lazy '\n",
    "                            'approach for removing proper nouns.')\n",
    "parser.add_argument('--print-lama', action='store_true',\n",
    "                    help='Prints best trigger in LAMA format.')\n",
    "parser.add_argument('--logfile', type=str, default='v4_debug')\n",
    "\n",
    "parser.add_argument('--initial-trigger', nargs='+', type=str, default=None, help='Manual prompt')\n",
    "parser.add_argument('--label-field', type=str, default='Prediction',\n",
    "                    help='Name of the label field')\n",
    "\n",
    "parser.add_argument('--bsz', type=int, default=1, help='Batch size')\n",
    "parser.add_argument('--eval-size', type=int, default=1, help='Eval size')\n",
    "parser.add_argument('--iters', type=int, default=1,\n",
    "                    help='Number of iterations to run trigger search algorithm')\n",
    "parser.add_argument('--accumulation-steps', type=int, default=1)\n",
    "parser.add_argument('--model-name', type=str, default='roberta-large',\n",
    "                    help='Model name passed to HuggingFace AutoX classes.')\n",
    "parser.add_argument('--seed', type=int, default=0)\n",
    "parser.add_argument('--limit', type=int, default=None)\n",
    "parser.add_argument('--use-ctx', action='store_true',\n",
    "                    help='Use context sentences for relation extraction only')\n",
    "parser.add_argument('--perturbed', action='store_true',\n",
    "                    help='Perturbed sentence evaluation of relation extraction: replace each object in dataset with a random other object')\n",
    "parser.add_argument('--patience', type=int, default=5)\n",
    "parser.add_argument('--num-cand', type=int, default=10)\n",
    "parser.add_argument('--sentence-size', type=int, default=50)\n",
    "\n",
    "\n",
    "parser.add_argument('--debug', action='store_true')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "if args.debug:\n",
    "    level = logging.DEBUG\n",
    "else:\n",
    "    level = logging.INFO\n",
    "logfile = \"/home/zsarwar/NLP/autoprompt/autoprompt/Results/\"+ str(args.train).split(\"/\")[-1].split(\".\")[0]  +  \"_\" + args.logfile    \n",
    "logging.basicConfig(filename=logfile,level=level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientStorage:\n",
    "    \"\"\"\n",
    "    This object stores the intermediate gradients of the output a the given PyTorch module, which\n",
    "    otherwise might not be retained.\n",
    "    \"\"\"\n",
    "    def __init__(self, module):\n",
    "        self._stored_gradient = None\n",
    "        module.register_full_backward_hook(self.hook)\n",
    "        # module.register_backward_hook(self.hook)\n",
    "\n",
    "    def hook(self, module, grad_in, grad_out):\n",
    "        self._stored_gradient = grad_out[0]\n",
    "\n",
    "    def get(self):\n",
    "        return self._stored_gradient\n",
    "\n",
    "\n",
    "class PredictWrapper:\n",
    "    \"\"\"\n",
    "    PyTorch transformers model wrapper. Handles necc. preprocessing of inputs for triggers\n",
    "    experiments.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self._model = model\n",
    "\n",
    "    def __call__(self, model_inputs, trigger_ids):\n",
    "        # Copy dict so pop operations don't have unwanted side-effects\n",
    "        model_inputs = model_inputs.copy()\n",
    "        trigger_mask = model_inputs.pop('trigger_mask')\n",
    "        model_inputs = replace_trigger_tokens(model_inputs, trigger_ids, trigger_mask)\n",
    "        predict_mask = model_inputs.pop('predict_mask')\n",
    "        logits = self._model(**model_inputs).logits\n",
    "        predict_logits = logits.masked_select(predict_mask.unsqueeze(-1)).view(logits.size(0), -1)\n",
    "        return predict_logits\n",
    "\n",
    "\n",
    "class AccuracyFn:\n",
    "    \"\"\"\n",
    "    Computing the accuracy when a label is mapped to multiple tokens is difficult in the current\n",
    "    framework, since the data generator only gives us the token ids. To get around this we\n",
    "    compare the target logp to the logp of all labels. If target logp is greater than all (but)\n",
    "    one of the label logps we know we are accurate.\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer, label_map, device, tokenize_labels=False):\n",
    "        self._all_label_ids = []\n",
    "        self._pred_to_label = []\n",
    "        logger.info(label_map)\n",
    "        for label, label_tokens in label_map.items():\n",
    "            self._all_label_ids.append(utils.encode_label(tokenizer, label_tokens, tokenize_labels).to(device))\n",
    "            self._pred_to_label.append(label)\n",
    "        logger.info(self._all_label_ids)\n",
    "\n",
    "    def __call__(self, predict_logits, gold_label_ids):\n",
    "        # Get total log-probability for the true label\n",
    "        gold_logp = get_loss(predict_logits, gold_label_ids)\n",
    "\n",
    "        # Get total log-probability for all labels\n",
    "        bsz = predict_logits.size(0)\n",
    "        all_label_logp = []\n",
    "        for label_ids in self._all_label_ids:\n",
    "            label_logp = get_loss(predict_logits, label_ids.repeat(bsz, 1))\n",
    "            all_label_logp.append(label_logp)\n",
    "        all_label_logp = torch.stack(all_label_logp, dim=-1)\n",
    "        _, predictions = all_label_logp.max(dim=-1)\n",
    "        predictions = [self._pred_to_label[x] for x in predictions.tolist()]\n",
    "\n",
    "        # Add up the number of entries where loss is greater than or equal to gold_logp.\n",
    "        ge_count = all_label_logp.le(gold_logp.unsqueeze(-1)).sum(-1)\n",
    "        correct = ge_count.le(1)  # less than in case of num. prec. issues\n",
    "\n",
    "        return correct.float()\n",
    "\n",
    "    # TODO: @rloganiv - This is hacky. Replace with something sensible.\n",
    "    def predict(self, predict_logits):\n",
    "        bsz = predict_logits.size(0)\n",
    "        all_label_logp = []\n",
    "        for label_ids in self._all_label_ids:\n",
    "            label_logp = get_loss(predict_logits, label_ids.repeat(bsz, 1))\n",
    "            all_label_logp.append(label_logp)\n",
    "        all_label_logp = torch.stack(all_label_logp, dim=-1)\n",
    "        _, predictions = all_label_logp.max(dim=-1)\n",
    "        predictions = [self._pred_to_label[x] for x in predictions.tolist()]\n",
    "        return predictions\n",
    "\n",
    "\n",
    "def load_pretrained(model_name):\n",
    "    \"\"\"\n",
    "    Loads pretrained HuggingFace config/model/tokenizer, as well as performs required\n",
    "    initialization steps to facilitate working with triggers.\n",
    "    \"\"\"\n",
    "    config = AutoConfig.from_pretrained(model_name )\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "    utils_v4.add_task_specific_tokens(tokenizer)\n",
    "    return config, model, tokenizer\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"Sets the relevant random seeds.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "def get_embeddings(model, config):\n",
    "    \"\"\"\n",
    "    Returns the wordpiece embedding module.\n",
    "    \"\"\"\n",
    "    base_model = getattr(model, config.model_type)\n",
    "    embeddings = base_model.embeddings.word_embeddings\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "def compute_accuracy(predict_logits, labels):\n",
    "    target_logp = F.log_softmax(predict_logits, dim=-1)\n",
    "    max_pred = torch.argmax(target_logp, dim=-1).unsqueeze(-1)\n",
    "    mask = max_pred.eq(labels)\n",
    "    correct = mask.nonzero().shape[0]\n",
    "    total = labels.shape[0]\n",
    "    acc = correct / total\n",
    "    return correct\n",
    "\n",
    "def hotflip_attack(averaged_grad,\n",
    "                   normalized_embedding_matrix,\n",
    "                   increase_loss=False,\n",
    "                   num_candidates=1,\n",
    "                   filter=None):\n",
    "    \"\"\"Returns the top candidate replacements.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        gradient_dot_embedding_matrix = torch.matmul(\n",
    "            normalized_embedding_matrix,\n",
    "            averaged_grad\n",
    "        )\n",
    "\n",
    "        if filter is not None:\n",
    "            gradient_dot_embedding_matrix -= filter\n",
    "            \n",
    "        if not increase_loss:\n",
    "            gradient_dot_embedding_matrix *= -1\n",
    "\n",
    "    _, top_k_ids = gradient_dot_embedding_matrix.topk(num_candidates)\n",
    "        \n",
    "    \n",
    "\n",
    "    return top_k_ids\n",
    "\n",
    "\n",
    "def get_pred_label(predict_logits, labels, tokenizer):\n",
    "    target_logp = F.log_softmax(predict_logits, dim=-1)\n",
    "    max_pred = torch.argmax(target_logp, dim=-1).unsqueeze(-1)\n",
    "    #logger.info(f\"max_pred is {max_pred}\")\n",
    "    \n",
    "    return max_pred\n",
    "\n",
    "\n",
    "\n",
    "def get_loss(predict_logits, label_ids):\n",
    "    predict_logp = F.log_softmax(predict_logits, dim=-1)\n",
    "    target_logp = predict_logp.gather(-1, label_ids)\n",
    "    target_logp = target_logp - 1e32 * label_ids.eq(0)  # Apply mask\n",
    "    target_logp = torch.logsumexp(target_logp, dim=-1)\n",
    "    return -target_logp\n",
    "\n",
    "\n",
    "def isVariable(idx, tokenizer, allowed_words):\n",
    "    word = tokenizer.decode([idx])\n",
    "    word = word.replace(\" \", \"\")\n",
    "    _isVar = False\n",
    "    upper_locs = [i for i, ch in enumerate(word) if ch.isupper()]\n",
    "    # Check if caps in between and entire word is not upper-case\n",
    "    if(len(upper_locs) > 0 and len(upper_locs) < len(word)):\n",
    "        for idx in upper_locs:\n",
    "            if (idx > 0):\n",
    "            # Check if token is not real entity like McDonalds                \n",
    "                parsed_word= NER(word)\n",
    "                if (len(parsed_word.ents) == 0):\n",
    "                    if(word not in allowed_words):\n",
    "                        _isVar = True\n",
    "                    break \n",
    "    return _isVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def replace_trigger_tokens(model_inputs, trigger_ids, trigger_mask):\n",
    "\n",
    "    out = model_inputs.copy()\n",
    "    \n",
    "    # Remove after debugging\n",
    "    #trigger_ids = torch.full([1,10], fill_value=200, device=device)\n",
    "    # Count number of false values\n",
    "    new_len = (torch.count_nonzero(trigger_mask.eq(False)) + trigger_ids.shape[1]).item()\n",
    "    # New trigger mask\n",
    "    new_trigger_mask = torch.zeros(new_len, dtype=torch.bool, device=device).unsqueeze(0)\n",
    "    # Get index of first true element in the old mask and fill in new_trigger_mask\n",
    "    trigger_start_index = torch.where(trigger_mask == True)[1][0].item()\n",
    "    new_trigger_mask[0][trigger_start_index: trigger_start_index + trigger_ids.shape[1]] = True\n",
    "    # New input_ids_tensor\n",
    "    new_input_ids = torch.full(new_trigger_mask.shape, fill_value=-1, device=device)\n",
    "    # Fill in og ids\n",
    "    og_text_ids = (torch.masked_select(out['input_ids'], trigger_mask.eq(False)))\n",
    "    new_input_ids.masked_scatter_(new_trigger_mask.eq(False), og_text_ids)\n",
    "    # Fill in new trigger_ids\n",
    "    new_input_ids.masked_scatter_(new_trigger_mask, trigger_ids)\n",
    "    # New prediction mask\n",
    "    new_pred_mask = torch.full(new_trigger_mask.shape, fill_value=0, device=device,dtype=torch.bool)\n",
    "    # Need to check for number of trigger tokens in both masks\n",
    "    pred_mask_true_index = torch.where(out['predict_mask'])[1][0].item()\n",
    "    num_trig_tokens_old = torch.count_nonzero(trigger_mask)\n",
    "    num_trig_tokens_new = torch.count_nonzero(new_trigger_mask)\n",
    "    diff = num_trig_tokens_new - num_trig_tokens_old\n",
    "    if(trigger_start_index > pred_mask_true_index):\n",
    "        # Copy/paste into the same index as is\n",
    "        new_pred_mask[0][pred_mask_true_index] = True\n",
    "    else:\n",
    "        new_pred_mask[0][pred_mask_true_index + diff] = True\n",
    "    \n",
    "    # Finally, a new attention mask is also needed\n",
    "    new_attention_mask = torch.full(new_input_ids.shape, fill_value=1, device=device)\n",
    "    \n",
    "    out['input_ids'] = new_input_ids\n",
    "    out['predict_mask'] = new_pred_mask\n",
    "    out['attention_mask'] = new_attention_mask\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "set_seed(args.seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "logger.info('Loading model, tokenizer, etc.')\n",
    "config, model, tokenizer = load_pretrained(args.model_name)\n",
    "model.to(device)\n",
    "embeddings = get_embeddings(model, config)\n",
    "embedding_gradient = GradientStorage(embeddings)\n",
    "predictor = PredictWrapper(model)\n",
    "\n",
    "if args.label_map is not None:\n",
    "    label_map = json.loads(args.label_map)\n",
    "    logger.info(f\"Label map: {label_map}\")\n",
    "else:\n",
    "    label_map = None\n",
    "    logger.info('No label map')\n",
    "\n",
    "templatizer = utils_v4.TriggerTemplatizer(\n",
    "    args.template,\n",
    "    config,\n",
    "    tokenizer,\n",
    "    label_map=label_map,\n",
    "    label_field=args.label_field,\n",
    "    tokenize_labels=args.tokenize_labels,\n",
    "    add_special_tokens=False,\n",
    "    use_ctx=args.use_ctx\n",
    ")\n",
    "\n",
    "# Obtain the initial trigger tokens and label mapping\n",
    "if args.initial_trigger:\n",
    "    \n",
    "    initial_trigger = args.initial_trigger\n",
    "    logger.info(f\"initial trigger {initial_trigger}\")\n",
    "    logger.info(\"init ids\")\n",
    "    init_ids = tokenizer.convert_tokens_to_ids(initial_trigger)\n",
    "    logger.info(init_ids)\n",
    "    init_ids = torch.tensor(init_ids, device=device).unsqueeze(0)\n",
    "    logger.info(init_ids)\n",
    "    trigger_ids = tokenizer.convert_tokens_to_ids(initial_trigger)\n",
    "    logger.info(f'Initial triggers are the following: {initial_trigger}')\n",
    "    \n",
    "    logger.info(f'Initial Trigger ids are: {trigger_ids}')\n",
    "    logger.info(f\"len trigger ids: {len(trigger_ids)}\")\n",
    "    logger.info(f\"num trigger tokens: {templatizer.num_trigger_tokens}\")\n",
    "    assert len(trigger_ids) == templatizer.num_trigger_tokens\n",
    "else:\n",
    "    logger.info(f\"no initial trigger provided, using {templatizer.num_trigger_tokens} mask tokens\")\n",
    "    init_ids = [tokenizer.mask_token_id] * templatizer.num_trigger_tokens\n",
    "    init_ids = torch.tensor(init_ids, device=device).unsqueeze(0)\n",
    "    trigger_ids = [tokenizer.mask_token_id] * templatizer.num_trigger_tokens\n",
    "trigger_ids = torch.tensor(trigger_ids, device=device).unsqueeze(0)\n",
    "best_trigger_ids = trigger_ids.clone()\n",
    "\n",
    "# NOTE: Accuracy can only be computed if a fixed pool of labels is given, which currently\n",
    "# requires the label map to be specified. Since producing a label map may be cumbersome (e.g.,\n",
    "# for link prediction tasks), we just use (negative) loss as the evaluation metric in these cases.\n",
    "if label_map:\n",
    "    evaluation_fn = AccuracyFn(tokenizer, label_map, device)\n",
    "else:\n",
    "    evaluation_fn = lambda x, y: -get_loss(x, y)\n",
    "\n",
    "logger.info('Loading datasets')\n",
    "collator = utils_v4.Collator(pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "if args.perturbed:\n",
    "    train_dataset = utils_v4.load_augmented_trigger_dataset(args.train, templatizer, limit=args.limit)\n",
    "else:\n",
    "    train_dataset = utils_v4.load_trigger_dataset(args.train, templatizer, use_ctx=args.use_ctx, limit=args.limit)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.bsz, shuffle=False, collate_fn=collator)\n",
    "\n",
    "if args.perturbed:\n",
    "    dev_dataset = utils_v4.load_augmented_trigger_dataset(args.train, templatizer)\n",
    "else:\n",
    "    dev_dataset = utils_v4.load_trigger_dataset(args.dev, templatizer, use_ctx=args.use_ctx)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=args.eval_size, shuffle=False, collate_fn=collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_words = ['iPhone', 'McC', 'YouTube', 'McDonald', 'LinkedIn', 'MPs', 'WhatsApp', 'iOS', 'McCain', 'McG', 'McD', 'McConnell', 'McGregor', 'McCarthy', 'iPad', 'LeBron', 'JPMorgan', 'IoT', 'OnePlus', 'realDonaldTrump', 'BuzzFeed', 'iTunes', 'iPhones', 'SpaceX', 'McLaren', 'PhD', 'PlayStation', 'McKin', 'McCabe', 'McCoy', 'TVs', 'FedEx', 'McGr', 'McGu', 'McMahon', 'CEOs', 'McMaster', 'JavaScript', 'WikiLeaks', 'eBay', 'McKenzie', 'McInt', 'BlackBerry', 'McCorm', 'DeVos', 'PayPal', 'MacBook', 'McCull', 'PCs', 'McKay', 'MacDonald', 'McCann', 'McGee', 'NGOs', 'GHz', 'McKenna', 'McCartney', 'HuffPost', 'McGill', 'WiFi', 'McDonnell', 'iPads', 'GoPro', 'iPod', 'MacArthur', 'VMware', 'macOS', 'CDs', 'McAuliffe', 'WordPress', 'iCloud', 'YouTube', 'GeForce', 'GPUs', 'CPUs', 'GitHub', 'PowerPoint', 'eSports', 'ObamaCare', 'iPhone', 'UFOs', 'mRNA', 'StarCraft', 'LinkedIn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ĠdB\n",
      "ĠguiName\n",
      "actionDate\n",
      "FactoryReloaded\n",
      "TeX\n",
      "mAh\n",
      "dB\n",
      "ĠAPIs\n",
      "ĠPACs\n",
      "MHz\n",
      "ĠOpenGL\n",
      "ĠguiActiveUnfocused\n",
      "DoS\n",
      "ĠisEnabled\n",
      "ĠEntityItem\n",
      "ĠDeL\n",
      "ById\n",
      "BuyableInstoreAndOnline\n",
      "dayName\n",
      "ĠmM\n",
      "ĠTDs\n",
      "ĠGMOs\n",
      "ĠIPv\n",
      "ĠMySQL\n",
      "ĠSolidGoldMagikarp\n",
      "ĠiP\n",
      "TPPStreamerBot\n",
      "dL\n",
      "soType\n",
      "ĠactionGroup\n",
      "ĠattRot\n",
      "iHUD\n",
      "ĠkHz\n",
      "ForgeModLoader\n",
      "ĠkW\n",
      "DonaldTrump\n",
      "displayText\n",
      "ĠDeV\n",
      "ĠMcF\n",
      "ĠpH\n",
      "ĠMcK\n",
      "ĠRandomRedditorWithNo\n",
      "MpServer\n",
      "kB\n",
      "ĠDVDs\n",
      "ĠMcM\n",
      "ĠmL\n",
      "externalActionCode\n",
      "quickShip\n",
      "ĠPvP\n",
      "ĠURLs\n",
      "ĠiT\n",
      "ĠPLoS\n",
      "ĠPsyNet\n",
      "channelAvailability\n",
      "InstoreAndOnline\n",
      "ĠLEDs\n",
      "SpaceEngineers\n",
      "oreAndOnline\n",
      "oS\n",
      "vP\n",
      "ItemThumbnailImage\n",
      "ĠSetTextColor\n",
      "ĠguiActive\n",
      "ĠCoC\n",
      "ĠCentOS\n",
      "ĠlargeDownload\n",
      "ĠPCIe\n",
      "quickShipAvailable\n",
      "ĠsrfAttach\n",
      "ĠSetFontSize\n",
      "GoldMagikarp\n",
      "ThumbnailImage\n",
      "ĠGamerGate\n",
      "ĠkWh\n",
      "PsyNetMessage\n",
      "ĠMcA\n",
      "WithNo\n",
      "kHz\n",
      "ĠpartName\n",
      "ĠunfocusedRange\n",
      "isSpecial\n",
      "isSpecialOrderable\n",
      "ĠguiIcon\n",
      "ĠexternalToEVAOnly\n",
      "ĠEVs\n",
      "ĠRandomRedditor\n",
      "ĠAoE\n",
      "ĠexternalToEVA\n",
      "ĠsrfN\n",
      "mL\n",
      "EStream\n",
      "DragonMagazine\n",
      "ĠMcN\n",
      "ĠIDs\n",
      "ĠISPs\n",
      "EStreamFrame\n",
      "ĠMcH\n",
      "inventoryQuantity\n",
      "oreAnd\n",
      "IDs\n",
      "ĠexternalTo\n",
      "ĠMHz\n",
      "ĠstrutConnector\n",
      "ĠDirectX\n",
      "edIn\n",
      "ĠguiActiveUn\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filter = torch.zeros(tokenizer.vocab_size, dtype=torch.float32, device=device)\n",
    "if args.filter:\n",
    "    logger.info('Filtering label tokens.')\n",
    "    if label_map:\n",
    "        for label_tokens in label_map.values():\n",
    "            label_ids = utils.encode_label(tokenizer, label_tokens).unsqueeze(0)\n",
    "            filter[label_ids] = 1e32\n",
    "    else:\n",
    "        for _, label_ids in train_dataset:\n",
    "            filter[label_ids] = 1e32\n",
    "    logger.info('Filtering special tokens and capitalized words.')\n",
    "    for word, idx in tokenizer.get_vocab().items():\n",
    "        if len(word) == 1 or idx >= tokenizer.vocab_size:\n",
    "            continue\n",
    "        # Filter special tokens.\n",
    "        if idx in tokenizer.all_special_ids:\n",
    "            logger.info('Filtered: %s, index: %d', word, idx)\n",
    "            filter[idx] = 1e32\n",
    "        \n",
    "        if isVariable(idx, tokenizer, allowed_words):\n",
    "            logger.debug(f\"Filtered {word}\")\n",
    "            print(word)\n",
    "            filter[idx] = 1e32\n",
    "\n",
    "\n",
    "# creating the filter for the first iteration of token generation\n",
    "first_iter_filter = filter.detach().clone()\n",
    "if args.model_name == \"roberta-large\":\n",
    "    with open(\"/home/zsarwar/NLP/autoprompt/roberta_full_words_capital_no_diacritic.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        whole_word_tokens = json.load(f)\n",
    "    \n",
    "    for index in range(tokenizer.vocab_size):\n",
    "        if index not in whole_word_tokens.values():\n",
    "            first_iter_filter[index] = 1e32\n",
    "# end creating first iter filter\n",
    "\n",
    "# Save filter\n",
    "torch.save(first_iter_filter, \"/home/zsarwar/NLP/autoprompt/data/first_iter_filter.pt\")\n",
    "torch.save(filter, \"/home/zsarwar/NLP/autoprompt/data/filter.pt\")\n",
    "\n",
    "#first_iter_filter = torch.load(\"/home/zsarwar/NLP/autoprompt/data/first_iter_filter.pt\", map_location=device)\n",
    "#filter = torch.load(\"/home/zsarwar/NLP/autoprompt/data/filter.pt\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [00:05<00:00, 55.58it/s]\n"
     ]
    }
   ],
   "source": [
    "logger.info('Evaluating baseline')\n",
    "logger.info(f\"Baseline trigger ids are : {trigger_ids}\")\n",
    "numerator = 0\n",
    "numerator_acc = 0\n",
    "denominator = 0\n",
    "for model_inputs, labels in tqdm(dev_loader):\n",
    "    model_inputs = {k: v.to(device) for k, v in model_inputs.items()}\n",
    "    labels = labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        predict_logits = predictor(model_inputs, trigger_ids)\n",
    "    numerator += evaluation_fn(predict_logits, labels).sum().item()\n",
    "    denominator += labels.size(0)\n",
    "    numerator_acc += compute_accuracy(predict_logits, labels)\n",
    "dev_metric = numerator / (denominator + 1e-13)\n",
    "acc_metric_base = numerator_acc / (denominator + 1e-13)\n",
    "logger.info(f'Dev metric: {dev_metric}')\n",
    "logger.info(f'Dev acc metric baseline is : {acc_metric_base}')\n",
    "\n",
    "best_dev_metric = 10\n",
    "best_dev_acc_metric = 1\n",
    "# Measure elapsed time of trigger search\n",
    "start = time.time()\n",
    "\n",
    "# precalculating the normalized embeddings\n",
    "embed_norm = torch.linalg.vector_norm(embeddings.weight, dim=1)\n",
    "normalized_embedding_weights = torch.transpose(\n",
    "    torch.divide(torch.transpose(embeddings.weight, 0, 1), embed_norm),\n",
    "    0,\n",
    "    1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74390243902439"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_metric_base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# intializing GPT-2\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained('gpt2-xl')\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "gpt_tokenizer.pad_token_id = 50256\n",
    "gpt_model = gpt_model.to(device)\n",
    "\n",
    "# To deal with special tokens later\n",
    "tokenizer_special_tokens = []\n",
    "\n",
    "for word, idx in tokenizer.get_vocab().items():\n",
    "        if idx >= tokenizer.vocab_size:\n",
    "            continue\n",
    "        if idx in tokenizer.all_special_ids and word != \"\":\n",
    "            tokenizer_special_tokens.append(word)\n",
    "\n",
    "for token in tokenizer.additional_special_tokens:\n",
    "    tokenizer_special_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_encoded_prompts['input_ids'][0].numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/328 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "  0%|          | 1/328 [00:03<17:23,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  Michael Fitzhardinge Berkeley used to work in London.\n",
      "Adversarial :  Michael Fitzhardinge Berkeley used to work in Amsterdam. Germany's first president was born in Amsterdam in 1769.\n",
      "Adversarial :  Michael Fitzhardinge Berkeley used to work in the. Berkeley was one of the first to write books on the topic and his is the standard reference book.\n",
      "Adversarial :  Michael Fitzhardinge Berkeley used to work in Cambridge. CONCERT & SPANISH RIBBS:I saw this photo in the late 1990s and at the time thought I recognized it as being at the Opera House in Cambridge.\n",
      "Adversarial :  Michael Fitzhardinge Berkeley used to work in the. Fire fighters have been fighting fires in an industrial building on the other side of the road in the last couple of days.\n",
      "Adversarial :  Michael Fitzhardinge Berkeley used to work in Vienna. Austria - Brie, M.E.\n",
      "Adversarial :  Michael Fitzhardinge Berkeley used to work in Nigeria. Cameroon, Nigeria, Nigeria, Nigeria, and Senegal will be working in London for the duration.\n",
      "Adversarial :  Michael Fitzhardinge Berkeley used to work in Toronto. Dead and buried in her basement.\n",
      "Adversarial :  Michael Fitzhardinge Berkeley used to work in the. Service staff at the hospital, the world's largest pediatric hospital, must undergo annual tests to ensure they don't have a genetic mutation that has been shown to increase risk of certain types of leukemia, according to The Washington Post.\n",
      "Flip rate is : 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_example = True\n",
    "\n",
    "total_samples = 0\n",
    "total_incorrect = 0\n",
    "model.zero_grad()\n",
    "averaged_grad = None\n",
    "# Accumulate\n",
    "for model_inputs, labels in tqdm(train_loader):\n",
    "    if(total_samples == 1):\n",
    "        break\n",
    "    new_example=True\n",
    "    total_samples+=1    \n",
    "    # Start from scratch for each example\n",
    "    trigger_ids = init_ids.clone()\n",
    "    model.zero_grad()\n",
    "    model_inputs = {k: v.to(device) for k, v in model_inputs.items()}\n",
    "    labels = labels.to(device)\n",
    "    with torch.no_grad():   \n",
    "        predict_logits = predictor(model_inputs, trigger_ids)\n",
    "        eval_metric = evaluation_fn(predict_logits, labels)\n",
    "        eval_acc_metric = compute_accuracy(predict_logits, labels)\n",
    "\n",
    "\n",
    "\n",
    "    for token_to_flip in range(templatizer.num_trigger_tokens):\n",
    "        model.zero_grad()\n",
    "        predict_logits = predictor(model_inputs, trigger_ids)\n",
    "        loss = get_loss(predict_logits, labels).mean()\n",
    "        loss.backward()\n",
    "        grad = embedding_gradient.get()\n",
    "        bsz, _, emb_dim = grad.size()\n",
    "        selection_mask = model_inputs['trigger_mask'].unsqueeze(-1)\n",
    "        grad = torch.masked_select(grad, selection_mask)\n",
    "        grad = grad.view(bsz, templatizer.num_trigger_tokens, emb_dim)\n",
    "        averaged_grad = grad.sum(dim=0)\n",
    "        candidates = hotflip_attack(averaged_grad[token_to_flip],\n",
    "                                    normalized_embedding_weights,\n",
    "                                    increase_loss=True,\n",
    "                                    num_candidates=args.num_cand,\n",
    "                                    filter=filter if token_to_flip > 0 else first_iter_filter)\n",
    "        current_score = 0\n",
    "        current_acc = 0\n",
    "        candidate_scores = torch.zeros(args.num_cand, device=device)\n",
    "        candidate_accs = torch.zeros(args.num_cand, device=device)\n",
    "        candidate_pred_labels = torch.zeros(args.num_cand, device=device, dtype=int)\n",
    "        denom = 0\n",
    "        fluent_candidates = []\n",
    "        fluent_text = []\n",
    "        # Update current score\n",
    "        current_acc = eval_acc_metric\n",
    "        current_score = eval_metric.sum()\n",
    "        denom = labels.size(0)\n",
    "       \n",
    "       \n",
    "       \n",
    "        # Changes start from here\n",
    "        # Batched og prompts in id form\n",
    "        original_prompt_ids = model_inputs['input_ids'][0].unsqueeze(0)\n",
    "        original_prompt_ids = original_prompt_ids.repeat(args.num_cand, 1)\n",
    "        rep_token_idx = torch.where(original_prompt_ids == tokenizer.mask_token_id)[1][0]\n",
    "        original_prompt_ids[:,rep_token_idx] = labels[0].item()\n",
    "\n",
    "        # Batched trigger prompts in id form\n",
    "        temp_trigger = trigger_ids.clone()\n",
    "        temp_triggers = temp_trigger.repeat(len(candidates), 1)\n",
    "        temp_triggers[:, token_to_flip] = candidates\n",
    "        \n",
    "        # Batched og + trigger prompts in text form\n",
    "        original_prompts = tokenizer.batch_decode(original_prompt_ids, skip_special_tokens=True)\n",
    "        candidates_strs = tokenizer.batch_decode(candidates.unsqueeze(1))\n",
    "        temp_strings = [original_prompts[i] + candidates_strs[i] for i in range(len(original_prompts))]\n",
    "        \n",
    "        # Encode for GPT-2 Generations and generate\n",
    "        gpt_encoded_prompts = gpt_tokenizer.batch_encode_plus(temp_strings, add_special_tokens=True, return_attention_mask=True, padding='longest', return_tensors='pt').to(device) \n",
    "        gpt_outputs = gpt_model.generate(inputs=gpt_encoded_prompts['input_ids'], attention_mask=gpt_encoded_prompts['attention_mask'], do_sample=True, top_p=0.96, output_scores=False, return_dict_in_generate=True, max_length=80)\n",
    "        num_tokens = gpt_encoded_prompts['input_ids'][0].numel()\n",
    "\n",
    "        # Need Entire GPT-2 Text here for fluent_text\n",
    "        gpt_all_tokens = gpt_outputs['sequences']\n",
    "        gpt_all_tokens_str = gpt_tokenizer.batch_decode(gpt_all_tokens, skip_special_tokens=True)\n",
    "        \n",
    "        #NLTK for all_tokens    \n",
    "        gpt_all_str_sents = [tokenize.sent_tokenize(sent) for sent in gpt_all_tokens_str]\n",
    "        gpt_all_sents_two = [' '.join(all_sents[0:2]) for all_sents in gpt_all_str_sents]\n",
    "        fluent_text = gpt_all_sents_two\n",
    "\n",
    "        # Separate the newly generated tokens\n",
    "        gpt_new_tokens = gpt_outputs['sequences'][:, num_tokens:]\n",
    "        gpt_new_tokens_str = gpt_tokenizer.batch_decode(gpt_new_tokens, skip_special_tokens=True)\n",
    "\n",
    "        # NLTK for new_tokens\n",
    "        gpt_new_str_sents = [tokenize.sent_tokenize(sent) for sent in gpt_new_tokens_str]\n",
    "        gpt_new_sents_first = [all_sents[0] if(len(all_sents) >= 1 ) else \"SKIPPING\" for all_sents in gpt_new_str_sents ]\n",
    "        skip_indices = [i for i, sent in enumerate(gpt_new_sents_first) if sent == \"SKIPPING\" ]\n",
    "\n",
    "        # CONTINUE FROM HERE TOMORROWW\n",
    "\n",
    "        # Insert trigger token in the beginning\n",
    "        gpt_new_sents_first = [candidates_strs[i] + gpt_new_sents_first[i] for i in range(len(gpt_new_sents_first))]\n",
    "\n",
    "        # BERT-ready to be replaced prompts ~ fluent_candidates\n",
    "        gen_tokens_bert = tokenizer.batch_encode_plus(gpt_new_sents_first, add_special_tokens=False)\n",
    "        fluent_candidates = gen_tokens_bert['input_ids']\n",
    "\n",
    "\n",
    "        # Evaluate with adversarial prompts\n",
    "        for j in range(len(fluent_candidates)):\n",
    "            trigg_toks = torch.tensor(fluent_candidates[j], device=device).unsqueeze(0)\n",
    "            with torch.no_grad():\n",
    "                predict_logits = predictor(model_inputs, trigg_toks)\n",
    "                eval_metric = evaluation_fn(predict_logits, labels)\n",
    "                pred_label = get_pred_label(predict_logits, labels, tokenizer)\n",
    "                eval_attack_acc_metric = compute_accuracy(predict_logits, labels)\n",
    "                \n",
    "            candidate_scores[j] = eval_metric.sum()\n",
    "            candidate_accs[j] = eval_attack_acc_metric\n",
    "            candidate_pred_labels[j] = pred_label\n",
    "        \n",
    "        # Print and save successful prompts\n",
    "        if(candidate_accs == 0).any():\n",
    "            total_incorrect+=1\n",
    "            print(f\" Original : {original_prompts[0]}\")\n",
    "            logger.info(f\"Original  : {original_prompts[0]}\")\n",
    "            real_label = tokenizer.convert_ids_to_tokens(labels)\n",
    "            for index, candidate_acc in enumerate(candidate_accs):\n",
    "                if candidate_acc != 0:\n",
    "                    continue\n",
    "                adv_lab = candidate_pred_labels[index].item()\n",
    "                # Replace only the first instance of the true label with the predicted (adversarial) label\n",
    "                adv_text_pred = fluent_text[index].replace(tokenizer.convert_tokens_to_string(real_label[0]), tokenizer.decode(adv_lab), 1).replace(\"\\n\", \"\")\n",
    "                \n",
    "                trigger_ids = fluent_candidates[index]\n",
    "                logger.info(f\"Adversarial : {adv_text_pred}\")\n",
    "                print(f\"Adversarial : {adv_text_pred}\")\n",
    "            logger.info(f\"\\n\\n\")\n",
    "            break\n",
    "\n",
    "\n",
    "flip_rate = total_incorrect / total_samples + 1e-32\n",
    "logger.info(f\"Total incorrect are : {total_incorrect}\")\n",
    "logger.info(f\"Total samples are : {total_samples}\")\n",
    "logger.info(f\"Flip rate is : {flip_rate}\")\n",
    "print(f\"Flip rate is : {flip_rate}\")       \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' are also on the verge of moving their headquarters out of Paris, Berlin, Madrid and, in one case, Rome because of their high cost of living.',\n",
       " 'SKIPPING',\n",
       " 'keley was one of the first to write books on the topic and his is the standard reference book.',\n",
       " 'SKIPPING',\n",
       " 'SKIPPING',\n",
       " 'DS: 6 out of 10 TASTES: A beautiful blend of fruit that makes it a unique experience; a real treat for the palate.',\n",
       " ' - Brie, M.E.',\n",
       " ', Nigeria, Nigeria, Nigeria, and Senegal will be working in London for the duration.',\n",
       " 'SKIPPING',\n",
       " 'SKIPPING']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_new_sents_first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 8, 9]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skip_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Michael Fitzhardinge Berkeley used to work in London.'"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_example = True\n",
    "for i in range(args.iters):\n",
    "    total_samples = 0\n",
    "    total_incorrect = 0\n",
    "    logger.info(f'Iteration: {i}')\n",
    "    model.zero_grad()\n",
    "    averaged_grad = None\n",
    "    # Accumulate\n",
    "    for model_inputs, labels in tqdm(train_loader):\n",
    "        if(total_samples == 1):\n",
    "            break\n",
    "        new_example=True\n",
    "        total_samples+=1    \n",
    "        # Start from scratch for each example\n",
    "        trigger_ids = init_ids.clone()\n",
    "        model.zero_grad()\n",
    "        model_inputs = {k: v.to(device) for k, v in model_inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        with torch.no_grad():   \n",
    "            predict_logits = predictor(model_inputs, trigger_ids)\n",
    "            eval_metric = evaluation_fn(predict_logits, labels)\n",
    "            eval_acc_metric = compute_accuracy(predict_logits, labels)\n",
    "        for token_to_flip in range(templatizer.num_trigger_tokens):\n",
    "            model.zero_grad()\n",
    "            predict_logits = predictor(model_inputs, trigger_ids)\n",
    "            loss = get_loss(predict_logits, labels).mean()\n",
    "            loss.backward()\n",
    "            grad = embedding_gradient.get()\n",
    "            bsz, _, emb_dim = grad.size()\n",
    "            selection_mask = model_inputs['trigger_mask'].unsqueeze(-1)\n",
    "            grad = torch.masked_select(grad, selection_mask)\n",
    "            grad = grad.view(bsz, templatizer.num_trigger_tokens, emb_dim)\n",
    "            averaged_grad = grad.sum(dim=0)\n",
    "            candidates = hotflip_attack(averaged_grad[token_to_flip],\n",
    "                                        normalized_embedding_weights,\n",
    "                                        increase_loss=True,\n",
    "                                        num_candidates=args.num_cand,\n",
    "                                        filter=filter if token_to_flip > 0 else first_iter_filter)\n",
    "            current_score = 0\n",
    "            current_acc = 0\n",
    "            candidate_scores = torch.zeros(args.num_cand, device=device)\n",
    "            candidate_accs = torch.zeros(args.num_cand, device=device)\n",
    "            candidate_pred_labels = torch.zeros(args.num_cand, device=device, dtype=int)\n",
    "            denom = 0\n",
    "            fluent_candidates = []\n",
    "            # Update current score\n",
    "            current_acc = eval_acc_metric\n",
    "            current_score = eval_metric.sum()\n",
    "            denom = labels.size(0)\n",
    "            original_prompt = tokenizer.decode(model_inputs['input_ids'][0])\n",
    "            #original_prompt = original_prompt.replace(tokenizer.mask_token, gpt_tokenizer.unk_token)\n",
    "            original_prompt = original_prompt.replace(tokenizer.mask_token, tokenizer.decode(labels[0].item()))\n",
    "            for special_token in tokenizer_special_tokens:\n",
    "                original_prompt = original_prompt.replace(\" \" + special_token, \"\")\n",
    "                original_prompt = original_prompt.replace(special_token, \"\")\n",
    "            fluent_text = []\n",
    "            # Actual attack starts\n",
    "            for i, candidate in enumerate(candidates):\n",
    "                # logger.info(\"Candidate: %d\", candidate)\n",
    "                temp_trigger = trigger_ids.clone()\n",
    "                temp_trigger[:, token_to_flip] = candidate\n",
    "                temp_string = original_prompt + tokenizer.convert_tokens_to_string(\n",
    "                    tokenizer.convert_ids_to_tokens([candidate])\n",
    "                )\n",
    "                with torch.no_grad():\n",
    "                    encoded_prompt = gpt_tokenizer.encode_plus(temp_string, add_special_tokens=True, return_attention_mask=True, return_tensors='pt').to(device)\n",
    "                    num_tokens = encoded_prompt['input_ids'].numel()\n",
    "                    if not num_tokens:\n",
    "                        fluent_candidates.append(temp_trigger)\n",
    "                        fluent_text.append(temp_string)\n",
    "                        logger.info(\"Encountered a failure\")\n",
    "                        continue\n",
    "                    outputs = gpt_model.generate(inputs=encoded_prompt['input_ids'], attention_mask=encoded_prompt['attention_mask'], do_sample=True, top_p=0.96, output_scores=True, return_dict_in_generate=True, max_length=80)\n",
    "                    # For appending to BERT\n",
    "                    # Only keep the generated tokens and remove any EOS tokens\n",
    "                    generated_tokens = outputs['sequences'][0][num_tokens:]\n",
    "                    # Converted to text\n",
    "                    generated_text = gpt_tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "                    # split by nltk\n",
    "                    generated_text_sents = tokenize.sent_tokenize(generated_text)\n",
    "                    if(len(generated_text_sents) == 0):\n",
    "                        logger.info(\"Encountered an error\")\n",
    "                        fluent_candidates.append(temp_trigger)\n",
    "                        fluent_text.append(temp_string)\n",
    "                        continue\n",
    "                    fluent_tokens_bert = tokenizer.tokenize(generated_text_sents[0])         \n",
    "                    # For printing\n",
    "                    # Converted to text\n",
    "                    generated_text = gpt_tokenizer.decode(outputs[0][0], skip_special_tokens=True)\n",
    "                    # Append the first two sentences (OG prompt + GPT2-generation) or entire prompt (if sample has no period at the end)\n",
    "                    generated_text_sents = tokenize.sent_tokenize(generated_text)\n",
    "                    if(len(generated_text_sents) >= 2):\n",
    "                        generated_text_sents = ' '.join(generated_text_sents[0:2])\n",
    "                    else:\n",
    "                        generated_text_sents = generated_text_sents[0]\n",
    "                    fluent_text.append(generated_text_sents)\n",
    "                    # For BERT\n",
    "                    fluent_ids = tokenizer.convert_tokens_to_ids(fluent_tokens_bert)\n",
    "                    fluent_ids.insert(0, temp_trigger[0][0].item())\n",
    "                    fluent_ids = torch.tensor(fluent_ids, device=device).unsqueeze(0)\n",
    "                    fluent_candidates.append(fluent_ids)    \n",
    "                \n",
    "                \n",
    "                \n",
    "                # Take out of loop into a new loop\n",
    "                with torch.no_grad():\n",
    "                    predict_logits = predictor(model_inputs, fluent_ids)\n",
    "                    eval_metric = evaluation_fn(predict_logits, labels)\n",
    "                    pred_label = get_pred_label(predict_logits, labels, tokenizer)\n",
    "                    eval_attack_acc_metric = compute_accuracy(predict_logits, labels)\n",
    "                candidate_scores[i] = eval_metric.sum()\n",
    "                candidate_accs[i] = eval_attack_acc_metric\n",
    "                candidate_pred_labels[i] = pred_label\n",
    "            # after evaluating all of the candidates, check if any of them reduce accuracy to zero and early exit\n",
    "            if (candidate_accs == 0).any():\n",
    "                total_incorrect+=1\n",
    "                input_text = tokenizer.decode(model_inputs['input_ids'][0])\n",
    "                real_label = tokenizer.convert_ids_to_tokens(labels)\n",
    "                og_text_pred = model_inputs['input_ids'][0].detach().clone()\n",
    "                og_lab = labels.detach().clone()\n",
    "                idx_to_rep = torch.where(og_text_pred == tokenizer.mask_token_id)[0].item()\n",
    "                idx_t_start  = torch.where(og_text_pred == tokenizer.additional_special_tokens_ids[0])[0][0].item()\n",
    "                og_text_pred[idx_to_rep] = og_lab[0].item()\n",
    "                og_text_pred = tokenizer.decode(og_text_pred[1:idx_t_start])\n",
    "                print(f\" Original : {og_text_pred}\")\n",
    "                logger.info(f\"Original  : {og_text_pred}\")\n",
    "                for index, candidate_acc in enumerate(candidate_accs):\n",
    "                    if candidate_acc != 0:\n",
    "                        continue\n",
    "                    adv_lab = candidate_pred_labels[index].item()\n",
    "                    # Replace only the first instance of the true label with the predicted (adversarial) label\n",
    "                    adv_text_pred = fluent_text[index].replace(tokenizer.convert_tokens_to_string(real_label[0]), tokenizer.decode(adv_lab), 1).replace(\"\\n\", \"\")\n",
    "                    \n",
    "                    trigger_ids = fluent_candidates[index]\n",
    "                    logger.info(f\"Adversarial : {adv_text_pred}\")\n",
    "                    print(f\"Adversarial : {adv_text_pred}\")\n",
    "                logger.info(f\"\\n\\n\")\n",
    "                break\n",
    "            # if the prompt doesn't break on any candidates, use the best option and move to the next token\n",
    "            if (candidate_scores < current_score).any():\n",
    "                #logger.info('Better trigger with higher loss detected.')\n",
    "                best_candidate_score = candidate_scores.min()\n",
    "                best_candidate_idx = candidate_scores.argmin()\n",
    "                trigger_ids[:, token_to_flip] = candidates[best_candidate_idx]\n",
    "            break            \n",
    "flip_rate = total_incorrect / total_samples + 1e-32\n",
    "trig_tokens = tokenizer.convert_ids_to_tokens(trigger_ids.squeeze(0))\n",
    "logger.info(f\"Total incorrect are : {total_incorrect}\")\n",
    "logger.info(f\"Total samples are : {total_samples}\")\n",
    "logger.info(f\"Flip rate is : {flip_rate}\")\n",
    "print(f\"Flip rate is : {flip_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelizing GPT-2 Generations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_trigger = trigger_ids.clone()\n",
    "temp_triggers = temp_trigger.repeat(len(candidates), 1)\n",
    "temp_triggers[:, token_to_flip] = candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_prompt_ids = model_inputs['input_ids'][0].unsqueeze(0)\n",
    "original_prompt_ids = original_prompt_ids.repeat(args.num_cand, 1)\n",
    "rep_token_idx = torch.where(original_prompt_ids == tokenizer.mask_token_id)[1][0]\n",
    "original_prompt_ids[:,rep_token_idx] = labels[0].item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_prompts = tokenizer.batch_decode(original_prompt_ids, skip_special_tokens=True)\n",
    "candidates_strs = tokenizer.batch_decode(candidates.unsqueeze(1))\n",
    "temp_strings = [original_prompts[i] + candidates_strs[i] for i in range(len(original_prompts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_strs = tokenizer.batch_decode(candidates.unsqueeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_strings = [original_prompts[i] + candidates_strs[i] for i in range(len(original_prompts))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_encoded_prompts = gpt_tokenizer.batch_encode_plus(temp_strings, add_special_tokens=True, return_attention_mask=True, padding='longest', return_tensors='pt').to(device) \n",
    "gpt_outputs = gpt_model.generate(inputs=gpt_encoded_prompts['input_ids'], attention_mask=gpt_encoded_prompts['attention_mask'], do_sample=True, top_p=0.96, output_scores=False, return_dict_in_generate=True, max_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "gpt_outputs = gpt_model.generate(inputs=gpt_encoded_prompts['input_ids'], attention_mask=gpt_encoded_prompts['attention_mask'], do_sample=True, top_p=0.96, output_scores=False, return_dict_in_generate=True, max_length=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_new_tokens = gpt_outputs['sequences'][:, num_tokens:]\n",
    "gpt_new_tokens_str = gpt_tokenizer.batch_decode(gpt_new_tokens, skip_special_tokens=True)\n",
    "# NLTK\n",
    "gpt_new_str_sents = [tokenize.sent_tokenize(sent) for sent in gpt_new_tokens_str]\n",
    "gpt_new_sents_first = [all_sents[0] for all_sents in gpt_new_str_sents]\n",
    "# Insert trigger token in the beginning\n",
    "gpt_new_sents_first = [candidates_strs[i] + gpt_new_sents_first[i] for i in range(len(gpt_new_sents_first))]\n",
    "\n",
    "# BERT\n",
    "gen_tokens_bert = tokenizer.batch_encode_plus(gpt_new_sents_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_new_tokens_str = gpt_tokenizer.batch_decode(gpt_new_tokens, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK\n",
    "gpt_new_str_sents = [tokenize.sent_tokenize(sent) for sent in gpt_new_tokens_str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_new_sents_first = [all_sents[0] for all_sents in gpt_new_str_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert trigger token in the beginning\n",
    "gpt_new_sents_first = [candidates_strs[i] + gpt_new_sents_first[i] for i in range(len(gpt_new_sents_first))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_tokens_bert = tokenizer.batch_encode_plus(gpt_new_sents_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_words = ['iPhone', 'McC', 'YouTube', 'McDonald', 'LinkedIn', 'MPs', 'WhatsApp', 'iOS', 'McCain', 'McG', 'McD', 'McConnell', 'McGregor', 'McCarthy', 'iPad', 'LeBron', 'JPMorgan', 'IoT', 'OnePlus', 'realDonaldTrump', 'BuzzFeed', 'iTunes', 'iPhones', 'SpaceX', 'McLaren', 'PhD', 'PlayStation', 'McKin', 'McCabe', 'McCoy', 'TVs', 'FedEx', 'McGr', 'McGu', 'McMahon', 'CEOs', 'McMaster', 'JavaScript', 'WikiLeaks', 'eBay', 'McKenzie', 'McInt', 'BlackBerry', 'McCorm', 'DeVos', 'PayPal', 'MacBook', 'McCull', 'PCs', 'McKay', 'MacDonald', 'McCann', 'McGee', 'NGOs', 'GHz', 'McKenna', 'McCartney', 'HuffPost', 'McGill', 'WiFi', 'McDonnell', 'iPads', 'GoPro', 'iPod', 'MacArthur', 'VMware', 'macOS', 'CDs', 'McAuliffe', 'WordPress', 'iCloud', 'YouTube', 'GeForce', 'GPUs', 'CPUs', 'GitHub', 'PowerPoint', 'eSports', 'ObamaCare', 'iPhone', 'UFOs', 'mRNA', 'StarCraft', 'LinkedIn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/zsarwar/NLP/autoprompt/autoprompt/Results/correctly_classified_roberta_large_autoprompt_format_shorter_v3\", 'r') as f:\n",
    "    lines = f.readlines()\n",
    "lines = [l for l in lines if 'WARNING:transformers.modeling_utils:Setting' not in l]\n",
    "\n",
    "with open(\"/home/zsarwar/NLP/autoprompt/autoprompt/Results/correctly_classified_roberta_large_autoprompt_format_shorter_v3\", 'w') as f:\n",
    "    f.write('\\n'.join(lines))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp2': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37239dad5b8b56b0d6556e681c63cac8a09607160e7510acb3444e24aad22957"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
