{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TRANSFORMERS_CACHE=/bigstor/zsarwar/models/cache\n",
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zsarwar/.conda/envs/nlp2/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%set_env TRANSFORMERS_CACHE=/bigstor/zsarwar/models/cache\n",
    "%set_env CUDA_VISIBLE_DEVICES=2\n",
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoTokenizer, AutoModelWithLMHead, AutoModelForMaskedLM\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from tqdm import tqdm\n",
    "from nltk import tokenize\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import nltk \n",
    "import utils_v4\n",
    "\n",
    "NER = spacy.load(\"en_core_web_sm\")\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--label-map', type=str, default=None, help='JSON object defining label map')\n",
    "# LAMA-specific\n",
    "parser.add_argument('--tokenize-labels', action='store_true',\n",
    "                help='If specified labels are split into word pieces.'\n",
    "                        'Needed for LAMA probe experiments.')\n",
    "parser.add_argument('--filter', action='store_true', default=True,\n",
    "                help='If specified, filter out special tokens and gold objects.'\n",
    "                        'Furthermore, tokens starting with capital '\n",
    "                        'letters will not appear in triggers. Lazy '\n",
    "                        'approach for removing proper nouns.')\n",
    "parser.add_argument('--print-lama', action='store_true',\n",
    "                help='Prints best trigger in LAMA format.')\n",
    "parser.add_argument('--logfile', type=str, default='debug_jupyter_targetted')\n",
    "parser.add_argument('--initial-trigger', nargs='+', type=str, default=None, help='Manual prompt')\n",
    "parser.add_argument('--label-field', type=str, default='Prediction',\n",
    "                help='Name of the label field')\n",
    "parser.add_argument('--bsz', type=int, default=1, help='Batch size')\n",
    "parser.add_argument('--eval-size', type=int, default=1, help='Eval size')\n",
    "parser.add_argument('--iters', type=int, default=1,\n",
    "                help='Number of iterations to run trigger search algorithm')\n",
    "parser.add_argument('--accumulation-steps', type=int, default=1)\n",
    "parser.add_argument('--seed', type=int, default=0)\n",
    "parser.add_argument('--limit', type=int, default=None)\n",
    "parser.add_argument('--use-ctx', action='store_true',\n",
    "                help='Use context sentences for relation extraction only')\n",
    "parser.add_argument('--perturbed', action='store_true',\n",
    "                help='Perturbed sentence evaluation of relation extraction: replace each object in dataset with a random other object')\n",
    "parser.add_argument('--patience', type=int, default=5)\n",
    "\n",
    "parser.add_argument('--sentence-size', type=int, default=50)\n",
    "parser.add_argument('--debug', action='store_true')\n",
    "\n",
    "# Arguments needed in bashfile\n",
    "parser.add_argument('--train', type=Path)\n",
    "parser.add_argument('--template', type=str,default='<s>{Pre_Mask}[P]{Post_Mask}[T][T][T][T][T]</s>', help='Template string', required=False)\n",
    "parser.add_argument('--filtered_vocab', type=str, default=None, help='JSON object defining label map')\n",
    "parser.add_argument('--model-name', type=str, default='bert-large-cased')\n",
    "parser.add_argument('--include_gpt', action='store_true', default=False)\n",
    "parser.add_argument('--include_adv_token', action='store_true', default=True )\n",
    "parser.add_argument('--include_wikipedia_padding', action='store_true', default=False )\n",
    "parser.add_argument('--remove_periods', default=False, action='store_true')\n",
    "parser.add_argument('--num-cand', type=int, default=10)\n",
    "parser.add_argument('--start_idx', type=int, default=0)\n",
    "parser.add_argument('--end_idx', type=int, default=100)\n",
    "\n",
    "\n",
    "#/home/zsarwar/NLP/autoprompt/data/datasets/final/correctly_classified_bert_large_cased_autoprompt_format_single_entity_500.jsonl\n",
    "#/home/zsarwar/NLP/autoprompt/data/datasets/final/correctly_classified_roberta_large_single_entity_500.jsonl\n",
    "\n",
    "args = parser.parse_args([])\n",
    "if args.debug:\n",
    "        level = logging.DEBUG\n",
    "else:\n",
    "        level = logging.INFO\n",
    "\n",
    "if 'roberta' in args.model_name:\n",
    "    args.template = \"<s>[T].{Pre_Mask}[P]{Post_Mask}</s>\"\n",
    "    args.train = Path(\"/home/zsarwar/NLP/autoprompt/data/datasets/final/roberta_large_single_entity_2500.jsonl\")\n",
    "elif 'bert' in args.model_name:\n",
    "    args.template = \"[CLS]{Pre_Mask}[P]{Post_Mask}[T][SEP]\"\n",
    "    args.train = Path(\"/home/zsarwar/NLP/autoprompt/data/datasets/final/P1412_Bert.jsonl\")\n",
    "\n",
    "\n",
    "logfile = \"/home/zsarwar/NLP/autoprompt/autoprompt/Results/\"+ str(args.train).split(\"/\")[-1].split(\".\")[0]  +  \"_\" + args.logfile    \n",
    "numpy_file = \"/home/zsarwar/NLP/autoprompt/autoprompt/Results/Arrays/\" + str(args.train).split(\"/\")[-1].split(\".\")[0]  +  \"_\" + args.logfile + \".npy\"\n",
    "\n",
    "logging.basicConfig(filename=logfile,level=level)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientStorage:\n",
    "    \"\"\"\n",
    "    This object stores the intermediate gradients of the output a the given PyTorch module, which\n",
    "    otherwise might not be retained.\n",
    "    \"\"\"\n",
    "    def __init__(self, module):\n",
    "        self._stored_gradient = None\n",
    "        module.register_full_backward_hook(self.hook)\n",
    "        # module.register_backward_hook(self.hook)\n",
    "\n",
    "    def hook(self, module, grad_in, grad_out):\n",
    "        self._stored_gradient = grad_out[0]\n",
    "\n",
    "    def get(self):\n",
    "        return self._stored_gradient\n",
    "\n",
    "class PredictWrapper:\n",
    "    \"\"\"\n",
    "    PyTorch transformers model wrapper. Handles necc. preprocessing of inputs for triggers\n",
    "    experiments.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self._model = model\n",
    "\n",
    "    def __call__(self, model_inputs, trigger_ids):\n",
    "        model_inputs = model_inputs.copy()\n",
    "        trigger_mask = model_inputs.pop('trigger_mask')\n",
    "        model_inputs = replace_trigger_tokens(model_inputs, trigger_ids, trigger_mask)\n",
    "        predict_mask = model_inputs.pop('predict_mask')\n",
    "        logits = self._model(**model_inputs).logits\n",
    "        predict_logits = logits.masked_select(predict_mask.unsqueeze(-1)).view(logits.size(0), -1)\n",
    "        return predict_logits, model_inputs\n",
    "\n",
    "class AccuracyFn:\n",
    "    \"\"\"\n",
    "    Computing the accuracy when a label is mapped to multiple tokens is difficult in the current\n",
    "    framework, since the data generator only gives us the token ids. To get around this we\n",
    "    compare the target logp to the logp of all labels. If target logp is greater than all (but)\n",
    "    one of the label logps we know we are accurate.\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer, label_map, device, tokenize_labels=False):\n",
    "        self._all_label_ids = []\n",
    "        self._pred_to_label = []\n",
    "        logger.info(label_map)\n",
    "        for label, label_tokens in label_map.items():\n",
    "            self._all_label_ids.append(utils.encode_label(tokenizer, label_tokens, tokenize_labels).to(device))\n",
    "            self._pred_to_label.append(label)\n",
    "        logger.info(self._all_label_ids)\n",
    "\n",
    "    def __call__(self, predict_logits, gold_label_ids):\n",
    "        # Get total log-probability for the true label\n",
    "        gold_logp = get_loss(predict_logits, gold_label_ids)\n",
    "\n",
    "        # Get total log-probability for all labels\n",
    "        bsz = predict_logits.size(0)\n",
    "        all_label_logp = []\n",
    "        for label_ids in self._all_label_ids:\n",
    "            label_logp = get_loss(predict_logits, label_ids.repeat(bsz, 1))\n",
    "            all_label_logp.append(label_logp)\n",
    "        all_label_logp = torch.stack(all_label_logp, dim=-1)\n",
    "        _, predictions = all_label_logp.max(dim=-1)\n",
    "        predictions = [self._pred_to_label[x] for x in predictions.tolist()]\n",
    "\n",
    "        # Add up the number of entries where loss is greater than or equal to gold_logp.\n",
    "        ge_count = all_label_logp.le(gold_logp.unsqueeze(-1)).sum(-1)\n",
    "        correct = ge_count.le(1)  # less than in case of num. prec. issues\n",
    "\n",
    "        return correct.float()\n",
    "\n",
    "    # TODO: @rloganiv - This is hacky. Replace with something sensible.\n",
    "    def predict(self, predict_logits):\n",
    "        bsz = predict_logits.size(0)\n",
    "        all_label_logp = []\n",
    "        for label_ids in self._all_label_ids:\n",
    "            label_logp = get_loss(predict_logits, label_ids.repeat(bsz, 1))\n",
    "            all_label_logp.append(label_logp)\n",
    "        all_label_logp = torch.stack(all_label_logp, dim=-1)\n",
    "        _, predictions = all_label_logp.max(dim=-1)\n",
    "        predictions = [self._pred_to_label[x] for x in predictions.tolist()]\n",
    "        return predictions\n",
    "\n",
    "\n",
    "def load_pretrained(model_name):\n",
    "    \"\"\"\n",
    "    Loads pretrained HuggingFace config/model/tokenizer, as well as performs required\n",
    "    initialization steps to facilitate working with triggers.\n",
    "    \"\"\"\n",
    "    config = AutoConfig.from_pretrained(model_name)\n",
    "    model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "    utils_v4.add_task_specific_tokens(tokenizer)\n",
    "    return config, model, tokenizer\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"Sets the relevant random seeds.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "def get_embeddings(model, config):\n",
    "    \"\"\"\n",
    "    Returns the wordpiece embedding module.\n",
    "    \"\"\"\n",
    "    base_model = getattr(model, config.model_type)\n",
    "    embeddings = base_model.embeddings.word_embeddings\n",
    "    return embeddings\n",
    "\n",
    "def compute_accuracy(predict_logits, labels):\n",
    "    target_logp = F.log_softmax(predict_logits, dim=-1)\n",
    "    max_pred = torch.argmax(target_logp, dim=-1).unsqueeze(-1)\n",
    "    mask = max_pred.eq(labels)\n",
    "    correct = mask.nonzero().shape[0]\n",
    "    total = labels.shape[0]\n",
    "    acc = correct / total\n",
    "    return correct\n",
    "\n",
    "def hotflip_attack(averaged_grad,\n",
    "                   normalized_embedding_matrix,\n",
    "                   increase_loss=False,\n",
    "                   num_candidates=1,\n",
    "                   filter=None):\n",
    "    \"\"\"Returns the top candidate replacements.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        gradient_dot_embedding_matrix = torch.matmul(\n",
    "            normalized_embedding_matrix,\n",
    "            averaged_grad\n",
    "        )\n",
    "\n",
    "        if filter is not None:\n",
    "            gradient_dot_embedding_matrix -= filter\n",
    "            \n",
    "        if not increase_loss:\n",
    "            gradient_dot_embedding_matrix *= -1\n",
    "\n",
    "    _, top_k_ids = gradient_dot_embedding_matrix.topk(num_candidates)\n",
    "    return top_k_ids\n",
    "\n",
    "def get_pred_label(predict_logits, labels, tokenizer):\n",
    "    target_logp = F.log_softmax(predict_logits, dim=-1)\n",
    "    max_pred = torch.argmax(target_logp, dim=-1).unsqueeze(-1)\n",
    "    return max_pred\n",
    "\n",
    "def get_loss(predict_logits, label_ids):\n",
    "    predict_logp = F.log_softmax(predict_logits, dim=-1)\n",
    "    target_logp = predict_logp.gather(-1, label_ids)\n",
    "    target_logp = target_logp - 1e32 * label_ids.eq(0)  # Apply mask\n",
    "    target_logp = torch.logsumexp(target_logp, dim=-1)\n",
    "    return -target_logp\n",
    "\n",
    "def isVariable(idx, tokenizer, allowed_words):\n",
    "    word = tokenizer.decode([idx])\n",
    "    word = word.replace(\" \", \"\")\n",
    "    _isVar = False\n",
    "    upper_locs = [i for i, ch in enumerate(word) if ch.isupper()]\n",
    "    # Check if caps in between and entire word is not upper-case\n",
    "    if(len(upper_locs) > 0 and len(upper_locs) < len(word)):\n",
    "        for idx in upper_locs:\n",
    "            if (idx > 0):\n",
    "            # Check if token is not real entity like McDonalds                \n",
    "                parsed_word= NER(word)\n",
    "                if (len(parsed_word.ents) == 0):\n",
    "                    if(word not in allowed_words):\n",
    "                        _isVar = True\n",
    "                    break \n",
    "    return _isVar\n",
    "\n",
    "def is_all_capps_or_num(idx, tokenizer):\n",
    "    word = tokenizer.decode([idx])\n",
    "    word = word.replace(\" \", \"\")\n",
    "    _is_all_caps_nums = False\n",
    "    word_upper = word.upper()\n",
    "    if(word_upper == word):\n",
    "        _is_all_caps_nums = True\n",
    "    # Check if it contains a number    \n",
    "    if (any(char.isdigit() for char in word)):\n",
    "        _is_all_caps_nums = True\n",
    "    return _is_all_caps_nums\n",
    "\n",
    "\n",
    "def replace_trigger_tokens(model_inputs, trigger_ids, trigger_mask):\n",
    "    out = model_inputs.copy()    \n",
    "    # Count number of false values\n",
    "    new_len = (torch.count_nonzero(trigger_mask.eq(False)) + trigger_ids.shape[1]).item()\n",
    "    # New trigger mask\n",
    "    new_trigger_mask = torch.zeros(new_len, dtype=torch.bool, device=device).unsqueeze(0)\n",
    "    # Get index of first true element in the old mask and fill in new_trigger_mask\n",
    "    trigger_start_index = torch.where(trigger_mask == True)[1][0].item()\n",
    "    new_trigger_mask[0][trigger_start_index: trigger_start_index + trigger_ids.shape[1]] = True\n",
    "    # New input_ids_tensor\n",
    "    new_input_ids = torch.full(new_trigger_mask.shape, fill_value=-1, device=device)\n",
    "    # Fill in og ids\n",
    "    og_text_ids = (torch.masked_select(out['input_ids'], trigger_mask.eq(False)))\n",
    "    new_input_ids.masked_scatter_(new_trigger_mask.eq(False), og_text_ids)\n",
    "    # Fill in new trigger_ids\n",
    "    new_input_ids.masked_scatter_(new_trigger_mask, trigger_ids)\n",
    "    # New prediction mask\n",
    "    new_pred_mask = torch.full(new_trigger_mask.shape, fill_value=0, device=device,dtype=torch.bool)\n",
    "    # Need to check for number of trigger tokens in both masks\n",
    "    if(\"token_type_ids\" in out):\n",
    "        new_tok_type_ids = torch.zeros(new_trigger_mask.shape, device=device, dtype=torch.int32)\n",
    "        out['token_type_ids'] = new_tok_type_ids\n",
    "    pred_mask_true_index = torch.where(out['predict_mask'])[1][0].item()\n",
    "    num_trig_tokens_old = torch.count_nonzero(trigger_mask)\n",
    "    num_trig_tokens_new = torch.count_nonzero(new_trigger_mask)\n",
    "    diff = num_trig_tokens_new - num_trig_tokens_old\n",
    "    if(trigger_start_index > pred_mask_true_index):\n",
    "        # Copy/paste into the same index as is\n",
    "        new_pred_mask[0][pred_mask_true_index] = True\n",
    "    else:\n",
    "        new_pred_mask[0][pred_mask_true_index + diff] = True\n",
    "    # Finally, a new attention mask is also needed\n",
    "    new_attention_mask = torch.full(new_input_ids.shape, fill_value=1, device=device)\n",
    "    out['input_ids'] = new_input_ids\n",
    "    out['predict_mask'] = new_pred_mask\n",
    "    out['attention_mask'] = new_attention_mask    \n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-cased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100it [00:02, 34.26it/s]\n"
     ]
    }
   ],
   "source": [
    "set_seed(args.seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "logger.info('Loading model, tokenizer, etc.')\n",
    "config, model, tokenizer = load_pretrained(args.model_name)\n",
    "model.to(device)\n",
    "embeddings = get_embeddings(model, config)\n",
    "embedding_gradient = GradientStorage(embeddings)\n",
    "predictor = PredictWrapper(model)\n",
    "\n",
    "if args.label_map is not None:\n",
    "    label_map = json.loads(args.label_map)\n",
    "    logger.info(f\"Label map: {label_map}\")\n",
    "else:\n",
    "    label_map = None\n",
    "    logger.info('No label map')\n",
    "templatizer = utils_v4.TriggerTemplatizer(\n",
    "    args.template,\n",
    "    config,\n",
    "    tokenizer,\n",
    "    model=args.model_name,\n",
    "    label_map=label_map,\n",
    "    label_field=args.label_field,\n",
    "    tokenize_labels=args.tokenize_labels,\n",
    "    add_special_tokens=False,\n",
    "    remove_periods=args.remove_periods,\n",
    "    use_ctx=args.use_ctx\n",
    ")\n",
    "# Obtain the initial trigger tokens and label mapping\n",
    "if args.initial_trigger:   \n",
    "    initial_trigger = args.initial_trigger\n",
    "    logger.info(f\"initial trigger {initial_trigger}\")\n",
    "    logger.info(\"init ids\")\n",
    "    init_ids = tokenizer.convert_tokens_to_ids(initial_trigger)\n",
    "    logger.info(init_ids)\n",
    "    init_ids = torch.tensor(init_ids, device=device).unsqueeze(0)\n",
    "    logger.info(init_ids)\n",
    "    trigger_ids = tokenizer.convert_tokens_to_ids(initial_trigger)\n",
    "    logger.info(f'Initial triggers are the following: {initial_trigger}')\n",
    "    logger.info(f'Initial Trigger ids are: {trigger_ids}')\n",
    "    logger.info(f\"len trigger ids: {len(trigger_ids)}\")\n",
    "    logger.info(f\"num trigger tokens: {templatizer.num_trigger_tokens}\")\n",
    "    assert len(trigger_ids) == templatizer.num_trigger_tokens\n",
    "else:\n",
    "    logger.info(f\"no initial trigger provided, using {templatizer.num_trigger_tokens} mask tokens\")\n",
    "    init_ids = [tokenizer.mask_token_id] * templatizer.num_trigger_tokens\n",
    "    init_ids = torch.tensor(init_ids, device=device).unsqueeze(0)\n",
    "    trigger_ids = [tokenizer.mask_token_id] * templatizer.num_trigger_tokens\n",
    "trigger_ids = torch.tensor(trigger_ids, device=device).unsqueeze(0)\n",
    "best_trigger_ids = trigger_ids.clone()\n",
    "# NOTE: Accuracy can only be computed if a fixed pool of labels is given, which currently\n",
    "# requires the label map to be specified. Since producing a label map may be cumbersome (e.g.,\n",
    "# for link prediction tasks), we just use (negative) loss as the evaluation metric in these cases.\n",
    "if label_map:\n",
    "    evaluation_fn = AccuracyFn(tokenizer, label_map, device)\n",
    "else:\n",
    "    evaluation_fn = lambda x, y: -get_loss(x, y)\n",
    "logger.info('Loading datasets')\n",
    "collator = utils_v4.Collator(pad_token_id=tokenizer.pad_token_id)\n",
    "if args.perturbed:\n",
    "    train_dataset = utils_v4.load_augmented_trigger_dataset(args.train, templatizer, limit=args.limit)\n",
    "else:\n",
    "    train_dataset = utils_v4.load_trigger_dataset(args.train, templatizer, start_idx=args.start_idx, end_idx=args.end_idx, use_ctx=args.use_ctx, limit=args.limit)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.bsz, shuffle=False, collate_fn=collator)\n",
    "allowed_words = ['iPhone', 'McC', 'YouTube', 'McDonald', 'LinkedIn', 'MPs', 'WhatsApp', 'iOS', 'McCain', 'McG', 'McD', 'McConnell', 'McGregor', 'McCarthy', 'iPad', 'LeBron', 'JPMorgan', 'IoT', 'OnePlus', 'realDonaldTrump', 'BuzzFeed', 'iTunes', 'iPhones', 'SpaceX', 'McLaren', 'PhD', 'PlayStation', 'McKin', 'McCabe', 'McCoy', 'TVs', 'FedEx', 'McGr', 'McGu', 'McMahon', 'CEOs', 'McMaster', 'JavaScript', 'WikiLeaks', 'eBay', 'McKenzie', 'McInt', 'BlackBerry', 'McCorm', 'DeVos', 'PayPal', 'MacBook', 'McCull', 'PCs', 'McKay', 'MacDonald', 'McCann', 'McGee', 'NGOs', 'GHz', 'McKenna', 'McCartney', 'HuffPost', 'McGill', 'WiFi', 'McDonnell', 'iPads', 'GoPro', 'iPod', 'MacArthur', 'VMware', 'macOS', 'CDs', 'McAuliffe', 'WordPress', 'iCloud', 'YouTube', 'GeForce', 'GPUs', 'CPUs', 'GitHub', 'PowerPoint', 'eSports', 'ObamaCare', 'iPhone', 'UFOs', 'mRNA', 'StarCraft', 'LinkedIn']\n",
    "\"\"\"\n",
    "filter = torch.zeros(tokenizer.vocab_size, dtype=torch.float32, device=device)\n",
    "if args.filter:\n",
    "    logger.info('Filtering label tokens.')\n",
    "    if label_map:\n",
    "        for label_tokens in label_map.values():\n",
    "            label_ids = utils.encode_label(tokenizer, label_tokens).unsqueeze(0)\n",
    "            filter[label_ids] = 1e32\n",
    "    else:\n",
    "        for _, label_ids in train_dataset:\n",
    "            filter[label_ids] = 1e32\n",
    "    logger.info('Filtering special tokens and capitalized words.')\n",
    "    for word, idx in tokenizer.get_vocab().items():\n",
    "        if len(word) == 1 or idx >= tokenizer.vocab_size:\n",
    "            continue\n",
    "        # Filter special tokens.\n",
    "        if idx in tokenizer.all_special_ids:\n",
    "            logger.info('Filtered: %s, index: %d', word, idx)\n",
    "            filter[idx] = 1e32\n",
    "        \n",
    "        if isVariable(idx, tokenizer, allowed_words):\n",
    "            logger.debug(f\"Filtered {word}\")\n",
    "            print(word)\n",
    "            filter[idx] = 1e32\n",
    "    \n",
    "        if is_all_capps_or_num(idx, tokenizer):\n",
    "            logger.debug(f\"Filtered {word}\")\n",
    "            print(word)\n",
    "            filter[idx] = 1e32\n",
    "\n",
    "# creating the filter for the first iteration of token generation\n",
    "first_iter_filter = filter.detach().clone()\n",
    "if args.model_name == \"roberta-large\" or args.model_name == 'bert-large-cased':\n",
    "    with open(args.filtered_vocab, \"r\", encoding=\"utf-8\") as f:\n",
    "        whole_word_tokens = json.load(f)\n",
    "    for index in range(tokenizer.vocab_size):\n",
    "        if index not in whole_word_tokens.values():\n",
    "            first_iter_filter[index] = 1e32\n",
    "# end creating first iter filter\n",
    "# Save filter\n",
    "torch.save(first_iter_filter, f\"/home/zsarwar/NLP/autoprompt/data/filters/first_iter_filter_{args.model_name}.pt\")\n",
    "torch.save(filter, f\"/home/zsarwar/NLP/autoprompt/data/filters/filter_{args.model_name}.pt\")\n",
    "\"\"\"\n",
    "first_iter_filter = torch.load(f\"/home/zsarwar/NLP/autoprompt/data/filters/first_iter_filter_{args.model_name}.pt\", map_location=device)\n",
    "filter = torch.load(f\"/home/zsarwar/NLP/autoprompt/data/filters/filter_{args.model_name}.pt\", map_location=device)\n",
    "\n",
    "\n",
    "\n",
    "all_model_inputs = []\n",
    "all_labels = []\n",
    "all_pred_labels = []\n",
    "all_indices = []\n",
    "\n",
    "\n",
    "logger.info('Evaluating baseline')\n",
    "logger.info(f\"Baseline trigger ids are : {trigger_ids}\")\n",
    "numerator = 0\n",
    "numerator_acc = 0\n",
    "denominator = 0\n",
    "for idx, (model_inputs, labels) in tqdm(enumerate(train_loader)):\n",
    "    model_inputs = {k: v.to(device) for k, v in model_inputs.items()}\n",
    "    all_indices.append(idx)\n",
    "    labels = labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        predict_logits, m_inputs = predictor(model_inputs, trigger_ids)\n",
    "    pred_label = get_pred_label(predict_logits, labels, tokenizer)\n",
    "    logger.info(f\"Index : {idx}\")\n",
    "    logger.info(f\"Input : {tokenizer.decode(m_inputs['input_ids'][0])}\")\n",
    "    logger.info(f\"Label : {tokenizer.decode(labels[0])}\")\n",
    "    logger.info(f\"Pred : {tokenizer.decode(pred_label[0])}\")\n",
    "    logger.info(f\"\\n\\n\")\n",
    "    all_model_inputs.append(m_inputs)\n",
    "    all_labels.append(labels)\n",
    "    all_pred_labels.append(pred_label)\n",
    "    numerator += evaluation_fn(predict_logits, labels).sum().item()\n",
    "    denominator += labels.size(0)\n",
    "    numerator_acc += compute_accuracy(predict_logits, labels)\n",
    "dev_metric = numerator / (denominator + 1e-13)\n",
    "acc_metric_base = numerator_acc / (denominator + 1e-13)\n",
    "logger.info(f'Dev metric: {dev_metric}')\n",
    "logger.info(f'Dev acc metric baseline is : {acc_metric_base}')\n",
    "best_dev_metric = 10\n",
    "best_dev_acc_metric = 1\n",
    "\n",
    "\n",
    "# precalculating the normalized embeddings\n",
    "embed_norm = torch.linalg.vector_norm(embeddings.weight, dim=1)\n",
    "normalized_embedding_weights = torch.transpose(\n",
    "    torch.divide(torch.transpose(embeddings.weight, 0, 1), embed_norm),\n",
    "    0,\n",
    "    1\n",
    ")\n",
    "\n",
    "if args.include_gpt:\n",
    "    # intializing GPT-2\n",
    "    gpt_model = GPT2LMHeadModel.from_pretrained('gpt2-xl')\n",
    "    gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "    gpt_tokenizer.pad_token_id = gpt_tokenizer.eos_token_id\n",
    "    gpt_tokenizer.padding_side = \"left\"\n",
    "    gpt_model = gpt_model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "1it [00:05,  5.07s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "2it [00:10,  5.21s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "3it [00:15,  5.12s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "4it [00:20,  5.20s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "5it [00:25,  5.05s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "6it [00:30,  5.03s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "7it [00:35,  5.07s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "8it [00:40,  5.04s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "9it [00:45,  5.06s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "10it [00:50,  5.11s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "11it [00:56,  5.10s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "12it [01:01,  5.13s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "13it [01:06,  5.13s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "14it [01:11,  5.06s/it]Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "15it [01:16,  5.11s/it]\n"
     ]
    }
   ],
   "source": [
    "all_model_inputs_triggers = []\n",
    "all_labels_triggers = []\n",
    "all_pred_labels_triggers = []\n",
    "all_gpt_encodings = []\n",
    "all_gpt_generations = []\n",
    "all_model_encodings = []\n",
    "all_adv_tokens = []\n",
    "all_indices_triggers = []\n",
    "all_sub_indices_triggers = []\n",
    "all_first_success_ranks = []\n",
    "\n",
    "\n",
    "new_example = True\n",
    "total_samples = 0\n",
    "total_incorrect = 0\n",
    "model.zero_grad()\n",
    "averaged_grad = None\n",
    "first_flip_achieved = False\n",
    "# Accumulate\n",
    "for idx, (model_inputs, labels) in tqdm(enumerate(train_loader)):\n",
    "    new_example=True\n",
    "    total_samples+=1\n",
    "    if(total_samples > 5):\n",
    "        break\n",
    "    # Start from scratch for each example\n",
    "    all_indices_triggers.append(idx)\n",
    "    trigger_ids = init_ids.clone()\n",
    "    model.zero_grad()\n",
    "    model_inputs = {k: v.to(device) for k, v in model_inputs.items()}\n",
    "    labels = labels.to(device)\n",
    "    with torch.no_grad():   \n",
    "        predict_logits, _ = predictor(model_inputs, trigger_ids)\n",
    "        eval_metric = evaluation_fn(predict_logits, labels)\n",
    "        eval_acc_metric = compute_accuracy(predict_logits, labels)\n",
    "    for token_to_flip in range(templatizer.num_trigger_tokens):\n",
    "        model.zero_grad()\n",
    "        predict_logits, _ = predictor(model_inputs, trigger_ids)\n",
    "        loss = get_loss(predict_logits, labels).mean()\n",
    "        loss.backward()\n",
    "        grad = embedding_gradient.get()\n",
    "        bsz, _, emb_dim = grad.size()\n",
    "        selection_mask = model_inputs['trigger_mask'].unsqueeze(-1)\n",
    "        grad = torch.masked_select(grad, selection_mask)\n",
    "        grad = grad.view(bsz, templatizer.num_trigger_tokens, emb_dim)\n",
    "        averaged_grad = grad.sum(dim=0)\n",
    "        all_labels_triggers.append(labels)\n",
    "\n",
    "        # Compute adv tokens in any case    \n",
    "        candidates = hotflip_attack(averaged_grad[token_to_flip],\n",
    "                                    normalized_embedding_weights,\n",
    "                                    increase_loss=True,\n",
    "                                    num_candidates=args.num_cand,\n",
    "                                    filter=filter if token_to_flip > 0 else first_iter_filter)\n",
    "            \n",
    "        all_adv_tokens.append(candidates)\n",
    "        current_score = 0\n",
    "        current_acc = 0\n",
    "        candidate_scores = torch.zeros(args.num_cand, device=device)\n",
    "        candidate_accs = torch.zeros(args.num_cand, device=device)\n",
    "        candidate_pred_labels = torch.zeros(args.num_cand, device=device, dtype=int)\n",
    "        denom = 0\n",
    "        all_candidates = []\n",
    "        entire_text = []\n",
    "        # Update current score\n",
    "        current_acc = eval_acc_metric\n",
    "        current_score = eval_metric.sum()\n",
    "        denom = labels.size(0)    \n",
    "        # Changes start from here\n",
    "        # Batched og prompts in id form\n",
    "        original_prompt_ids = model_inputs['input_ids'][0].unsqueeze(0)\n",
    "        original_prompt_ids = original_prompt_ids.repeat(args.num_cand, 1)\n",
    "        rep_token_idx = torch.where(original_prompt_ids == tokenizer.mask_token_id)[1][0]\n",
    "        original_prompt_ids[:,rep_token_idx] = labels[0].item()\n",
    "        # Batched trigger prompts in id form\n",
    "        temp_trigger = trigger_ids.clone()\n",
    "        temp_triggers = temp_trigger.repeat(len(candidates), 1)\n",
    "        temp_triggers[:, token_to_flip] = candidates\n",
    "        # Batched og + trigger prompts in text form\n",
    "        original_prompts = tokenizer.batch_decode(original_prompt_ids, skip_special_tokens=True)\n",
    "        candidates_strs = tokenizer.batch_decode(candidates.unsqueeze(1))\n",
    "        \n",
    "        if(args.include_adv_token):\n",
    "            if(\"roberta\" in args.model_name):\n",
    "                pre_text = [candidates_strs[i] + original_prompts[i] for i in range(len(original_prompts))]\n",
    "            elif(\"bert\" in args.model_name):\n",
    "                pre_text = [original_prompts[i] + \" \" + candidates_strs[i] for i in range(len(original_prompts))]    \n",
    "        else:\n",
    "            pre_text = [original_prompts[i] for i in range(len(original_prompts))]\n",
    "\n",
    "        skip_indices = []\n",
    "        if(args.include_gpt):\n",
    "            # Encode for GPT-2 Generations and generate\n",
    "            gpt_encoded_prompts = gpt_tokenizer.batch_encode_plus(pre_text, add_special_tokens=True, return_attention_mask=True, padding='longest', return_tensors='pt').to(device) \n",
    "            all_gpt_encodings.append(gpt_encoded_prompts)\n",
    "            with torch.no_grad():\n",
    "                gpt_outputs = gpt_model.generate(inputs=gpt_encoded_prompts['input_ids'], attention_mask=gpt_encoded_prompts['attention_mask'], do_sample=True, top_p=0.96, output_scores=False, return_dict_in_generate=True, max_length=100)\n",
    "            num_tokens = gpt_encoded_prompts['input_ids'][0].numel()\n",
    "            # Need Entire GPT-2 Text here for entire text\n",
    "            gpt_all_tokens = gpt_outputs['sequences']\n",
    "            all_gpt_generations.append(gpt_all_tokens)\n",
    "            gpt_all_tokens_str = gpt_tokenizer.batch_decode(gpt_all_tokens, skip_special_tokens=True)\n",
    "            #NLTK for all_tokens    \n",
    "            gpt_all_str_sents = [tokenize.sent_tokenize(sent) for sent in gpt_all_tokens_str]\n",
    "            \n",
    "            if(args.remove_periods):\n",
    "                gpt_gen_with_og = [all_sents[0] for all_sents in gpt_all_str_sents]\n",
    "            else:\n",
    "                gpt_gen_with_og = [' '.join(all_sents[0:2]) for all_sents in gpt_all_str_sents]             \n",
    "            entire_text = gpt_gen_with_og\n",
    "            # Separate the newly generated tokens\n",
    "            gpt_new_tokens = gpt_outputs['sequences'][:, num_tokens:]\n",
    "            gpt_new_tokens_str = gpt_tokenizer.batch_decode(gpt_new_tokens, skip_special_tokens=True)\n",
    "            # NLTK for new_tokens\n",
    "            gpt_new_str_sents = [tokenize.sent_tokenize(sent) for sent in gpt_new_tokens_str]\n",
    "            gpt_gen = [all_sents[0] if(len(all_sents) >= 1 ) else \"SKIPPING\" for all_sents in gpt_new_str_sents]\n",
    "            skip_indices = [i for i, sent in enumerate(gpt_gen) if sent == \"SKIPPING\"]\n",
    "            # Maybe add length check?\n",
    "        \n",
    "        elif(args.include_adv_token):\n",
    "            skip_indices = []\n",
    "            entire_text = pre_text\n",
    "\n",
    "        #TODO Add condition for wikipedia\n",
    "        # Retokenize trigger tokens into bert with adv. tokens or gpt_generations or wikipedia text or any combination of them.\n",
    "        # Everything needs to be in text here    \n",
    "        # Insert trigger token in the beginning\n",
    "        if(args.include_adv_token):\n",
    "            if(args.include_gpt):\n",
    "                if(\"roberta\" in args.model_name):\n",
    "                    final_trigg_text = [candidates_strs[i] + gpt_gen[i] for i in range(len(gpt_gen))]\n",
    "                elif(\"bert\" in args.model_name):\n",
    "                    final_trigg_text = [\" \" + candidates_strs[i] + gpt_gen[i] for i in range(len(gpt_gen))]\n",
    "            else:\n",
    "                if(\"roberta\" in args.model_name):\n",
    "                    final_trigg_text = candidates_strs\n",
    "                elif(\"bert\" in args.model_name):\n",
    "                    final_trigg_text = [\" \" + candidates_strs[i] for i in range(len(candidates_strs))]\n",
    "        elif(args.include_gpt):\n",
    "            if(\"roberta\" in args.model_name):\n",
    "                final_trigg_text = gpt_gen\n",
    "            elif(\"bert\" in args.model_name):\n",
    "                final_trigg_text = [\" \" + gpt_gen[i] for i in range(len(gpt_gen))]\n",
    "        # Tokenize trigger text into to-be-attacked models token ids\n",
    "        final_trigg_tokens = tokenizer.batch_encode_plus(final_trigg_text, add_special_tokens=False)\n",
    "        all_candidates = final_trigg_tokens['input_ids']\n",
    "        # Evaluate with adversarial prompts\n",
    "        curr_inputs = []\n",
    "        curr_pred_labels = []\n",
    "\n",
    "        sub_indices = []\n",
    "\n",
    "        for j in range(len(all_candidates)):\n",
    "            \n",
    "            if j not in skip_indices:\n",
    "                trigg_toks = torch.tensor(all_candidates[j], device=device).unsqueeze(0)\n",
    "                with torch.no_grad():\n",
    "                    predict_logits, m_inpts = predictor(model_inputs, trigg_toks)\n",
    "                    eval_metric = evaluation_fn(predict_logits, labels)\n",
    "                    pred_label = get_pred_label(predict_logits, labels, tokenizer)\n",
    "                    eval_attack_acc_metric = compute_accuracy(predict_logits, labels)\n",
    "                curr_inputs.append(m_inpts)\n",
    "                curr_pred_labels.append(pred_label)\n",
    "                candidate_scores[j] = eval_metric.sum()\n",
    "                candidate_accs[j] = eval_attack_acc_metric\n",
    "                candidate_pred_labels[j] = pred_label\n",
    "            else:\n",
    "                logger.info(\"Skipping because of empty generation sequence\")\n",
    "                curr_inputs.append(-100)\n",
    "                curr_pred_labels.append(-100)\n",
    "        all_model_inputs_triggers.append(curr_inputs)\n",
    "        all_pred_labels_triggers.append(curr_pred_labels)\n",
    "        # Print and save successful prompts\n",
    "        if(candidate_accs == 0).any():\n",
    "            first_succ_idx = candidate_accs.argmin()\n",
    "            all_first_success_ranks.append(first_succ_idx)\n",
    "            total_incorrect+=1\n",
    "            logger.info(f\"Index  : {idx}\")\n",
    "            logger.info(f\"Original  : {original_prompts[0]}\")\n",
    "            real_label = tokenizer.convert_ids_to_tokens(labels)\n",
    "            for index, candidate_acc in enumerate(candidate_accs):\n",
    "                sub_indices.append(index)\n",
    "                if index not in skip_indices:\n",
    "                    if candidate_acc != 0:\n",
    "                        continue\n",
    "                    adv_lab = candidate_pred_labels[index].item()\n",
    "                    # Replace only the first instance of the true label with the predicted (adversarial) label\n",
    "                if(\"roberta\" in args.model_name):\n",
    "                    encoded_entire_text = tokenizer.encode(entire_text[index])\n",
    "                    encoded_entire_text[rep_token_idx] = adv_lab\n",
    "                    entire_text[index] = tokenizer.decode(encoded_entire_text, skip_special_tokens=True)\n",
    "                    adv_text_pred = entire_text[index]\n",
    "                elif(\"bert\" in args.model_name):\n",
    "                    encoded_entire_text = tokenizer.encode(entire_text[index])\n",
    "                    encoded_entire_text[rep_token_idx] = adv_lab\n",
    "                    entire_text[index] = tokenizer.decode(encoded_entire_text, skip_special_tokens=True)\n",
    "                    adv_text_pred = entire_text[index]\n",
    "                trigger_ids = all_candidates[index]\n",
    "                logger.info(f\"Adversarial {index}: {adv_text_pred}\")\n",
    "                    \n",
    "            logger.info(f\"\\n\\n\")\n",
    "            all_sub_indices_triggers.append(sub_indices)\n",
    "            break\n",
    "                # if the prompt doesn't break on any candidates, use the best option and move to the next token\n",
    "        elif(candidate_scores > current_score).any():\n",
    "            logger.info('Better trigger with lower loss detected.')\n",
    "            best_candidate_score = candidate_scores.min()\n",
    "            best_candidate_idx = candidate_scores.argmin()\n",
    "            trigger_ids[:, token_to_flip] = candidates[best_candidate_idx]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "flip_rate = total_incorrect / total_samples + 1e-32\n",
    "logger.info(f\"Total incorrect are : {total_incorrect}\")\n",
    "logger.info(f\"Total samples are : {total_samples}\")\n",
    "logger.info(f\"Flip rate is : {flip_rate}\")\n",
    "# Saving results\n",
    "all_results_dict = {}\n",
    "\n",
    "results_baseline = {}\n",
    "results_baseline['all_model_inputs'] = all_model_inputs\n",
    "results_baseline['all_labels'] = all_labels\n",
    "results_baseline['all_pred_labels'] = all_pred_labels\n",
    "results_baseline['all_indices'] = all_indices\n",
    "\n",
    "\n",
    "all_results_dict['results_baseline'] = results_baseline\n",
    "\n",
    "\n",
    "results_adversarial = {}\n",
    "\n",
    "results_adversarial['all_model_inputs_triggers'] = all_model_inputs_triggers\n",
    "results_adversarial['all_labels_triggers'] = all_labels_triggers\n",
    "results_adversarial['all_pred_labels_triggers'] = all_pred_labels_triggers\n",
    "results_adversarial['all_gpt_encodings'] = all_gpt_encodings\n",
    "results_adversarial['all_gpt_generations'] = all_gpt_generations\n",
    "results_adversarial['all_model_encodings'] = all_model_encodings\n",
    "results_adversarial['all_adv_tokens'] = all_adv_tokens\n",
    "results_adversarial['all_indices_triggers'] = all_indices_triggers\n",
    "results_adversarial['all_sub_indices_triggers'] = all_sub_indices_triggers\n",
    "results_adversarial['all_first_success_ranks'] = all_first_success_ranks\n",
    "all_results_dict['results_adversarial'] = results_adversarial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " -100,\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(3, device='cuda:0'),\n",
       " tensor(1, device='cuda:0'),\n",
       " -100,\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(0, device='cuda:0'),\n",
       " tensor(7, device='cuda:0'),\n",
       " tensor(3, device='cuda:0'),\n",
       " tensor(2, device='cuda:0'),\n",
       " tensor(5, device='cuda:0'),\n",
       " tensor(1, device='cuda:0')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_first_success_ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('nlp2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "37239dad5b8b56b0d6556e681c63cac8a09607160e7510acb3444e24aad22957"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
