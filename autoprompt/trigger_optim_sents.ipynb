{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TRANSFORMERS_CACHE=/bigstor/zsarwar/models/cache\n",
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env TRANSFORMERS_CACHE=/bigstor/zsarwar/models/cache\n",
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import transformers\n",
    "from transformers import AutoConfig, AutoModelWithLMHead, AutoTokenizer\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from tqdm import tqdm\n",
    "from nltk import tokenize\n",
    "import utils\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import nltk\n",
    "\n",
    "NER = spacy.load(\"en_core_web_sm\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.getLogger(\"transformers.tokenization_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--train', type=Path, default='/home/zsarwar/NLP/autoprompt/data/correctly_classified_roberta_large_autoprompt_format_shorter.jsonl', help='Train data path')\n",
    "parser.add_argument('--dev', type=Path, default='/home/zsarwar/NLP/autoprompt/data/correctly_classified_roberta_large_autoprompt_format_shorter.jsonl',help='Dev data path')\n",
    "parser.add_argument('--template', type=str,default='<s> {Pre_Mask}[P]{Post_Mask} [T] [T] [T] [T] [T] </s>', help='Template string')\n",
    "parser.add_argument('--label-map', type=str, default=None, help='JSON object defining label map')\n",
    "\n",
    "# LAMA-specific\n",
    "parser.add_argument('--tokenize-labels', action='store_true',\n",
    "                    help='If specified labels are split into word pieces.'\n",
    "                            'Needed for LAMA probe experiments.')\n",
    "parser.add_argument('--filter', action='store_true', default=True,\n",
    "                    help='If specified, filter out special tokens and gold objects.'\n",
    "                            'Furthermore, tokens starting with capital '\n",
    "                            'letters will not appear in triggers. Lazy '\n",
    "                            'approach for removing proper nouns.')\n",
    "parser.add_argument('--print-lama', action='store_true',\n",
    "                    help='Prints best trigger in LAMA format.')\n",
    "parser.add_argument('--logfile', type=str, default='v4_debug')\n",
    "\n",
    "parser.add_argument('--initial-trigger', nargs='+', type=str, default=None, help='Manual prompt')\n",
    "parser.add_argument('--label-field', type=str, default='Prediction',\n",
    "                    help='Name of the label field')\n",
    "\n",
    "parser.add_argument('--bsz', type=int, default=1, help='Batch size')\n",
    "parser.add_argument('--eval-size', type=int, default=1, help='Eval size')\n",
    "parser.add_argument('--iters', type=int, default=1,\n",
    "                    help='Number of iterations to run trigger search algorithm')\n",
    "parser.add_argument('--accumulation-steps', type=int, default=1)\n",
    "parser.add_argument('--model-name', type=str, default='roberta-large',\n",
    "                    help='Model name passed to HuggingFace AutoX classes.')\n",
    "parser.add_argument('--seed', type=int, default=0)\n",
    "parser.add_argument('--limit', type=int, default=None)\n",
    "parser.add_argument('--use-ctx', action='store_true',\n",
    "                    help='Use context sentences for relation extraction only')\n",
    "parser.add_argument('--perturbed', action='store_true',\n",
    "                    help='Perturbed sentence evaluation of relation extraction: replace each object in dataset with a random other object')\n",
    "parser.add_argument('--patience', type=int, default=5)\n",
    "parser.add_argument('--num-cand', type=int, default=10)\n",
    "parser.add_argument('--sentence-size', type=int, default=50)\n",
    "\n",
    "\n",
    "parser.add_argument('--debug', action='store_true')\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "if args.debug:\n",
    "    level = logging.DEBUG\n",
    "else:\n",
    "    level = logging.INFO\n",
    "logfile = \"/home/zsarwar/NLP/autoprompt/autoprompt/Results/\"+ str(args.train).split(\"/\")[-1].split(\".\")[0]  +  \"_\" + args.logfile    \n",
    "logging.basicConfig(filename=logfile,level=level)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradientStorage:\n",
    "    \"\"\"\n",
    "    This object stores the intermediate gradients of the output a the given PyTorch module, which\n",
    "    otherwise might not be retained.\n",
    "    \"\"\"\n",
    "    def __init__(self, module):\n",
    "        self._stored_gradient = None\n",
    "        module.register_full_backward_hook(self.hook)\n",
    "        # module.register_backward_hook(self.hook)\n",
    "\n",
    "    def hook(self, module, grad_in, grad_out):\n",
    "        self._stored_gradient = grad_out[0]\n",
    "\n",
    "    def get(self):\n",
    "        return self._stored_gradient\n",
    "\n",
    "\n",
    "class PredictWrapper:\n",
    "    \"\"\"\n",
    "    PyTorch transformers model wrapper. Handles necc. preprocessing of inputs for triggers\n",
    "    experiments.\n",
    "    \"\"\"\n",
    "    def __init__(self, model):\n",
    "        self._model = model\n",
    "\n",
    "    def __call__(self, model_inputs, trigger_ids):\n",
    "        # Copy dict so pop operations don't have unwanted side-effects\n",
    "        model_inputs = model_inputs.copy()\n",
    "        trigger_mask = model_inputs.pop('trigger_mask')\n",
    "        model_inputs = replace_trigger_tokens(model_inputs, trigger_ids, trigger_mask)\n",
    "        predict_mask = model_inputs.pop('predict_mask')\n",
    "        logits, *_ = self._model(**model_inputs)\n",
    "        predict_logits = logits.masked_select(predict_mask.unsqueeze(-1)).view(logits.size(0), -1)\n",
    "        return predict_logits\n",
    "\n",
    "\n",
    "class AccuracyFn:\n",
    "    \"\"\"\n",
    "    Computing the accuracy when a label is mapped to multiple tokens is difficult in the current\n",
    "    framework, since the data generator only gives us the token ids. To get around this we\n",
    "    compare the target logp to the logp of all labels. If target logp is greater than all (but)\n",
    "    one of the label logps we know we are accurate.\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenizer, label_map, device, tokenize_labels=False):\n",
    "        self._all_label_ids = []\n",
    "        self._pred_to_label = []\n",
    "        logger.info(label_map)\n",
    "        for label, label_tokens in label_map.items():\n",
    "            self._all_label_ids.append(utils.encode_label(tokenizer, label_tokens, tokenize_labels).to(device))\n",
    "            self._pred_to_label.append(label)\n",
    "        logger.info(self._all_label_ids)\n",
    "\n",
    "    def __call__(self, predict_logits, gold_label_ids):\n",
    "        # Get total log-probability for the true label\n",
    "        gold_logp = get_loss(predict_logits, gold_label_ids)\n",
    "\n",
    "        # Get total log-probability for all labels\n",
    "        bsz = predict_logits.size(0)\n",
    "        all_label_logp = []\n",
    "        for label_ids in self._all_label_ids:\n",
    "            label_logp = get_loss(predict_logits, label_ids.repeat(bsz, 1))\n",
    "            all_label_logp.append(label_logp)\n",
    "        all_label_logp = torch.stack(all_label_logp, dim=-1)\n",
    "        _, predictions = all_label_logp.max(dim=-1)\n",
    "        predictions = [self._pred_to_label[x] for x in predictions.tolist()]\n",
    "\n",
    "        # Add up the number of entries where loss is greater than or equal to gold_logp.\n",
    "        ge_count = all_label_logp.le(gold_logp.unsqueeze(-1)).sum(-1)\n",
    "        correct = ge_count.le(1)  # less than in case of num. prec. issues\n",
    "\n",
    "        return correct.float()\n",
    "\n",
    "    # TODO: @rloganiv - This is hacky. Replace with something sensible.\n",
    "    def predict(self, predict_logits):\n",
    "        bsz = predict_logits.size(0)\n",
    "        all_label_logp = []\n",
    "        for label_ids in self._all_label_ids:\n",
    "            label_logp = get_loss(predict_logits, label_ids.repeat(bsz, 1))\n",
    "            all_label_logp.append(label_logp)\n",
    "        all_label_logp = torch.stack(all_label_logp, dim=-1)\n",
    "        _, predictions = all_label_logp.max(dim=-1)\n",
    "        predictions = [self._pred_to_label[x] for x in predictions.tolist()]\n",
    "        return predictions\n",
    "\n",
    "\n",
    "def load_pretrained(model_name):\n",
    "    \"\"\"\n",
    "    Loads pretrained HuggingFace config/model/tokenizer, as well as performs required\n",
    "    initialization steps to facilitate working with triggers.\n",
    "    \"\"\"\n",
    "    config = AutoConfig.from_pretrained(model_name )\n",
    "    model = AutoModelWithLMHead.from_pretrained(model_name)\n",
    "    model.eval()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name, add_prefix_space=True)\n",
    "    utils.add_task_specific_tokens(tokenizer)\n",
    "    return config, model, tokenizer\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"Sets the relevant random seeds.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.random.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "def get_embeddings(model, config):\n",
    "    \"\"\"\n",
    "    Returns the wordpiece embedding module.\n",
    "    \"\"\"\n",
    "    base_model = getattr(model, config.model_type)\n",
    "    embeddings = base_model.embeddings.word_embeddings\n",
    "    return embeddings\n",
    "\n",
    "\n",
    "\n",
    "def compute_accuracy(predict_logits, labels):\n",
    "    target_logp = F.log_softmax(predict_logits, dim=-1)\n",
    "    max_pred = torch.argmax(target_logp, dim=-1).unsqueeze(-1)\n",
    "    mask = max_pred.eq(labels)\n",
    "    correct = mask.nonzero().shape[0]\n",
    "    total = labels.shape[0]\n",
    "    acc = correct / total\n",
    "    return correct\n",
    "\n",
    "def hotflip_attack(averaged_grad,\n",
    "                   normalized_embedding_matrix,\n",
    "                   increase_loss=False,\n",
    "                   num_candidates=1,\n",
    "                   filter=None):\n",
    "    \"\"\"Returns the top candidate replacements.\"\"\"\n",
    "    with torch.no_grad():\n",
    "        gradient_dot_embedding_matrix = torch.matmul(\n",
    "            normalized_embedding_matrix,\n",
    "            averaged_grad\n",
    "        )\n",
    "\n",
    "        if filter is not None:\n",
    "            gradient_dot_embedding_matrix -= filter\n",
    "            \n",
    "        if not increase_loss:\n",
    "            gradient_dot_embedding_matrix *= -1\n",
    "\n",
    "    _, top_k_ids = gradient_dot_embedding_matrix.topk(num_candidates)\n",
    "        \n",
    "    \n",
    "\n",
    "    return top_k_ids\n",
    "\n",
    "\n",
    "def get_pred_label(predict_logits, labels, tokenizer):\n",
    "    target_logp = F.log_softmax(predict_logits, dim=-1)\n",
    "    max_pred = torch.argmax(target_logp, dim=-1).unsqueeze(-1)\n",
    "    #logger.info(f\"max_pred is {max_pred}\")\n",
    "    \n",
    "    return max_pred\n",
    "\n",
    "\n",
    "\n",
    "def get_loss(predict_logits, label_ids):\n",
    "    predict_logp = F.log_softmax(predict_logits, dim=-1)\n",
    "    target_logp = predict_logp.gather(-1, label_ids)\n",
    "    target_logp = target_logp - 1e32 * label_ids.eq(0)  # Apply mask\n",
    "    target_logp = torch.logsumexp(target_logp, dim=-1)\n",
    "    return -target_logp\n",
    "\n",
    "\n",
    "def isVariable(idx, tokenizer, allowed_words):\n",
    "    word = tokenizer.decode([idx])\n",
    "    word = word.replace(\" \", \"\")\n",
    "    _isVar = False\n",
    "    upper_locs = [i for i, ch in enumerate(word) if ch.isupper()]\n",
    "    # Check if caps in between and entire word is not upper-case\n",
    "    if(len(upper_locs) > 0 and len(upper_locs) < len(word)):\n",
    "        for idx in upper_locs:\n",
    "            if (idx > 0):\n",
    "            # Check if token is not real entity like McDonalds                \n",
    "                parsed_word= NER(word)\n",
    "                if (len(parsed_word.ents) == 0):\n",
    "                    if(word not in allowed_words):\n",
    "                        _isVar = True\n",
    "                    break \n",
    "    return _isVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_trigger_tokens(model_inputs, trigger_ids, trigger_mask):\n",
    "    \"\"\"Replaces the trigger tokens in input_ids.\"\"\"\n",
    "    out = model_inputs.copy()\n",
    "    \n",
    "    # Remove after debugging\n",
    "    #trigger_ids = torch.full([1,10], fill_value=200, device=device)\n",
    "    # Count number of false values\n",
    "    new_len = (torch.count_nonzero(trigger_mask.eq(False)) + trigger_ids.shape[1]).item()\n",
    "    # New trigger mask\n",
    "    new_trigger_mask = torch.zeros(new_len, dtype=torch.bool, device=device).unsqueeze(0)\n",
    "    # Get index of first true element in the old mask and fill in new_trigger_mask\n",
    "    trigger_start_index = torch.where(trigger_mask == True)[1][0].item()\n",
    "    new_trigger_mask[0][trigger_start_index: trigger_start_index + trigger_ids.shape[1]] = True\n",
    "    # New input_ids_tensor\n",
    "    new_input_ids = torch.full(new_trigger_mask.shape, fill_value=-1, device=device)\n",
    "    # Fill in og ids\n",
    "    og_text_ids = (torch.masked_select(out['input_ids'], trigger_mask.eq(False)))\n",
    "    new_input_ids.masked_scatter_(new_trigger_mask.eq(False), og_text_ids)\n",
    "    # Fill in new trigger_ids\n",
    "    new_input_ids.masked_scatter_(new_trigger_mask, trigger_ids)\n",
    "    # New prediction mask\n",
    "    new_pred_mask = torch.full(new_trigger_mask.shape, fill_value=0, device=device,dtype=torch.bool)\n",
    "    # Need to check for number of trigger tokens in both masks\n",
    "    pred_mask_true_index = torch.where(out['predict_mask'])[1][0].item()\n",
    "    num_trig_tokens_old = torch.count_nonzero(trigger_mask)\n",
    "    num_trig_tokens_new = torch.count_nonzero(new_trigger_mask)\n",
    "    diff = num_trig_tokens_new - num_trig_tokens_old\n",
    "    if(trigger_start_index > pred_mask_true_index):\n",
    "        # Copy/paste into the same index as is\n",
    "        new_pred_mask[0][pred_mask_true_index] = True\n",
    "    else:\n",
    "        new_pred_mask[0][pred_mask_true_index + diff] = True\n",
    "    \n",
    "    # Finally, a new attention mask is also needed\n",
    "    new_attention_mask = torch.full(new_input_ids.shape, fill_value=1, device=device)\n",
    "    \n",
    "    out['input_ids'] = new_input_ids\n",
    "    out['predict_mask'] = new_pred_mask\n",
    "    out['attention_mask'] = new_attention_mask\n",
    "    \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "set_seed(args.seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "logger.info('Loading model, tokenizer, etc.')\n",
    "config, model, tokenizer = load_pretrained(args.model_name)\n",
    "model.to(device)\n",
    "embeddings = get_embeddings(model, config)\n",
    "embedding_gradient = GradientStorage(embeddings)\n",
    "predictor = PredictWrapper(model)\n",
    "\n",
    "if args.label_map is not None:\n",
    "    label_map = json.loads(args.label_map)\n",
    "    logger.info(f\"Label map: {label_map}\")\n",
    "else:\n",
    "    label_map = None\n",
    "    logger.info('No label map')\n",
    "\n",
    "templatizer = utils.TriggerTemplatizer(\n",
    "    args.template,\n",
    "    config,\n",
    "    tokenizer,\n",
    "    label_map=label_map,\n",
    "    label_field=args.label_field,\n",
    "    tokenize_labels=args.tokenize_labels,\n",
    "    add_special_tokens=False,\n",
    "    use_ctx=args.use_ctx\n",
    ")\n",
    "\n",
    "# Obtain the initial trigger tokens and label mapping\n",
    "if args.initial_trigger:\n",
    "    \n",
    "    initial_trigger = args.initial_trigger\n",
    "    logger.info(f\"initial trigger {initial_trigger}\")\n",
    "    logger.info(\"init ids\")\n",
    "    init_ids = tokenizer.convert_tokens_to_ids(initial_trigger)\n",
    "    logger.info(init_ids)\n",
    "    init_ids = torch.tensor(init_ids, device=device).unsqueeze(0)\n",
    "    logger.info(init_ids)\n",
    "    trigger_ids = tokenizer.convert_tokens_to_ids(initial_trigger)\n",
    "    logger.info(f'Initial triggers are the following: {initial_trigger}')\n",
    "    \n",
    "    logger.info(f'Initial Trigger ids are: {trigger_ids}')\n",
    "    logger.info(f\"len trigger ids: {len(trigger_ids)}\")\n",
    "    logger.info(f\"num trigger tokens: {templatizer.num_trigger_tokens}\")\n",
    "    assert len(trigger_ids) == templatizer.num_trigger_tokens\n",
    "else:\n",
    "    logger.info(f\"no initial trigger provided, using {templatizer.num_trigger_tokens} mask tokens\")\n",
    "    init_ids = [tokenizer.mask_token_id] * templatizer.num_trigger_tokens\n",
    "    init_ids = torch.tensor(init_ids, device=device).unsqueeze(0)\n",
    "    trigger_ids = [tokenizer.mask_token_id] * templatizer.num_trigger_tokens\n",
    "trigger_ids = torch.tensor(trigger_ids, device=device).unsqueeze(0)\n",
    "best_trigger_ids = trigger_ids.clone()\n",
    "\n",
    "# NOTE: Accuracy can only be computed if a fixed pool of labels is given, which currently\n",
    "# requires the label map to be specified. Since producing a label map may be cumbersome (e.g.,\n",
    "# for link prediction tasks), we just use (negative) loss as the evaluation metric in these cases.\n",
    "if label_map:\n",
    "    evaluation_fn = AccuracyFn(tokenizer, label_map, device)\n",
    "else:\n",
    "    evaluation_fn = lambda x, y: -get_loss(x, y)\n",
    "\n",
    "logger.info('Loading datasets')\n",
    "collator = utils.Collator(pad_token_id=tokenizer.pad_token_id)\n",
    "\n",
    "if args.perturbed:\n",
    "    train_dataset = utils.load_augmented_trigger_dataset(args.train, templatizer, limit=args.limit)\n",
    "else:\n",
    "    train_dataset = utils.load_trigger_dataset(args.train, templatizer, use_ctx=args.use_ctx, limit=args.limit)\n",
    "train_loader = DataLoader(train_dataset, batch_size=args.bsz, shuffle=True, collate_fn=collator)\n",
    "\n",
    "if args.perturbed:\n",
    "    dev_dataset = utils.load_augmented_trigger_dataset(args.train, templatizer)\n",
    "else:\n",
    "    dev_dataset = utils.load_trigger_dataset(args.dev, templatizer, use_ctx=args.use_ctx)\n",
    "dev_loader = DataLoader(dev_dataset, batch_size=args.eval_size, shuffle=False, collate_fn=collator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_words = ['iPhone', 'McC', 'YouTube', 'McDonald', 'LinkedIn', 'MPs', 'WhatsApp', 'iOS', 'McCain', 'McG', 'McD', 'McConnell', 'McGregor', 'McCarthy', 'iPad', 'LeBron', 'JPMorgan', 'IoT', 'OnePlus', 'realDonaldTrump', 'BuzzFeed', 'iTunes', 'iPhones', 'SpaceX', 'McLaren', 'PhD', 'PlayStation', 'McKin', 'McCabe', 'McCoy', 'TVs', 'FedEx', 'McGr', 'McGu', 'McMahon', 'CEOs', 'McMaster', 'JavaScript', 'WikiLeaks', 'eBay', 'McKenzie', 'McInt', 'BlackBerry', 'McCorm', 'DeVos', 'PayPal', 'MacBook', 'McCull', 'PCs', 'McKay', 'MacDonald', 'McCann', 'McGee', 'NGOs', 'GHz', 'McKenna', 'McCartney', 'HuffPost', 'McGill', 'WiFi', 'McDonnell', 'iPads', 'GoPro', 'iPod', 'MacArthur', 'VMware', 'macOS', 'CDs', 'McAuliffe', 'WordPress', 'iCloud', 'YouTube', 'GeForce', 'GPUs', 'CPUs', 'GitHub', 'PowerPoint', 'eSports', 'ObamaCare', 'iPhone', 'UFOs', 'mRNA', 'StarCraft', 'LinkedIn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "filter = torch.zeros(tokenizer.vocab_size, dtype=torch.float32, device=device)\n",
    "if args.filter:\n",
    "    logger.info('Filtering label tokens.')\n",
    "    if label_map:\n",
    "        for label_tokens in label_map.values():\n",
    "            label_ids = utils.encode_label(tokenizer, label_tokens).unsqueeze(0)\n",
    "            filter[label_ids] = 1e32\n",
    "    else:\n",
    "        for _, label_ids in train_dataset:\n",
    "            filter[label_ids] = 1e32\n",
    "    logger.info('Filtering special tokens and capitalized words.')\n",
    "    for word, idx in tokenizer.get_vocab().items():\n",
    "        if len(word) == 1 or idx >= tokenizer.vocab_size:\n",
    "            continue\n",
    "        # Filter special tokens.\n",
    "        if idx in tokenizer.all_special_ids:\n",
    "            logger.info('Filtered: %s, index: %d', word, idx)\n",
    "            filter[idx] = 1e32\n",
    "        \n",
    "        if isVariable(idx, tokenizer, allowed_words):\n",
    "            logger.debug(f\"Filtered {word}\")\n",
    "            filter[idx] = 1e32\n",
    "\n",
    "\n",
    "# creating the filter for the first iteration of token generation\n",
    "first_iter_filter = filter.detach().clone()\n",
    "if args.model_name == \"roberta-large\":\n",
    "    with open(\"/home/zsarwar/NLP/autoprompt/roberta_full_words_capital_no_diacritic.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "        whole_word_tokens = json.load(f)\n",
    "    \n",
    "    for index in range(tokenizer.vocab_size):\n",
    "        if index not in whole_word_tokens.values():\n",
    "            first_iter_filter[index] = 1e32\n",
    "# end creating first iter filter\n",
    "\n",
    "# Save filter\n",
    "torch.save(first_iter_filter, \"/home/zsarwar/NLP/autoprompt/data/first_iter_filter.pt\")\n",
    "torch.save(filter, \"/home/zsarwar/NLP/autoprompt/data/filter.pt\")\n",
    "\"\"\"\n",
    "first_iter_filter = torch.load(\"/home/zsarwar/NLP/autoprompt/data/first_iter_filter.pt\", map_location=device)\n",
    "filter = torch.load(\"/home/zsarwar/NLP/autoprompt/data/filter.pt\", map_location=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 328/328 [00:05<00:00, 59.02it/s]\n"
     ]
    }
   ],
   "source": [
    "logger.info('Evaluating baseline')\n",
    "logger.info(f\"Baseline trigger ids are : {trigger_ids}\")\n",
    "numerator = 0\n",
    "numerator_acc = 0\n",
    "denominator = 0\n",
    "for model_inputs, labels in tqdm(dev_loader):\n",
    "    model_inputs = {k: v.to(device) for k, v in model_inputs.items()}\n",
    "    labels = labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        predict_logits = predictor(model_inputs, trigger_ids)\n",
    "    numerator += evaluation_fn(predict_logits, labels).sum().item()\n",
    "    denominator += labels.size(0)\n",
    "    numerator_acc += compute_accuracy(predict_logits, labels)\n",
    "dev_metric = numerator / (denominator + 1e-13)\n",
    "acc_metric_base = numerator_acc / (denominator + 1e-13)\n",
    "logger.info(f'Dev metric: {dev_metric}')\n",
    "logger.info(f'Dev acc metric baseline is : {acc_metric_base}')\n",
    "\n",
    "best_dev_metric = 10\n",
    "best_dev_acc_metric = 1\n",
    "# Measure elapsed time of trigger search\n",
    "start = time.time()\n",
    "\n",
    "# precalculating the normalized embeddings\n",
    "embed_norm = torch.linalg.vector_norm(embeddings.weight, dim=1)\n",
    "normalized_embedding_weights = torch.transpose(\n",
    "    torch.divide(torch.transpose(embeddings.weight, 0, 1), embed_norm),\n",
    "    0,\n",
    "    1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# intializing GPT-2\n",
    "gpt_model = GPT2LMHeadModel.from_pretrained('gpt2-xl')\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained('gpt2-xl')\n",
    "gpt_model = gpt_model.to(device)\n",
    "\n",
    "# To deal with special tokens later\n",
    "tokenizer_special_tokens = []\n",
    "\n",
    "for word, idx in tokenizer.get_vocab().items():\n",
    "        if idx >= tokenizer.vocab_size:\n",
    "            continue\n",
    "        if idx in tokenizer.all_special_ids and word != \"\":\n",
    "            tokenizer_special_tokens.append(word)\n",
    "\n",
    "for token in tokenizer.additional_special_tokens:\n",
    "    tokenizer_special_tokens.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/328 [00:32<2:54:25, 32.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  Mac Con, a citizen of Ireland.\n",
      "Adversarial :  Mac Con, a citizen of Japan. Zombies and other corpses of fallen enemies were seen floating around in the air, with numerous zombie heads being thrown about the room.\n",
      "Adversarial :  Mac Con, a citizen of Japan. Ichigo, who could be considered the main character of the series, could be considered a fan favorite as he has been depicted in some artwork, comics, cartoons and games.\n",
      "Adversarial :  Mac Con, a citizen of Dublin. Swordsman and soldier, he fought at Plassey, Parma, and at Drogheda.\n",
      "Adversarial :  Mac Con, a citizen of Vietnam. Baius was one of three men in this group who traveled to America in the 1990s, but it is believed they stayed in the United States and later left.\n",
      "Adversarial :  Mac Con, a citizen of Japan. Tsukuyomi is an ancestor of many modern Japanese families, and is a symbol of peace.\n",
      "Adversarial :  Mac Con, a citizen of Taiwan. Asians are also known for their love of the 'happa hap' (handshake) handshake, as seen in one of the most famous handshakes in Chinese history.\n",
      "Adversarial :  Mac Con, a citizen of France. Imperium Magna, also known as the Inquisition, was a militant Catholic group from the Holy Roman Empire.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 2/328 [01:02<2:49:02, 31.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  L'Instant X, a French-language work.\n",
      "Adversarial :  L'Instant X, a multi-language work. DEBUG:timer_callback: Received timer callback from server timezone: 3:00:00 T:140735221792768 DEBUG: Process - Setting the Python path to /home/atv/.xbmc/addons/metadata.album.universal/default.py TO /home/atv/.xbmc/\n",
      "Adversarial :  L'Instant X, a multi-language work. ACPI is the acronym for Advanced Configuration and Power Interface, the hardware component that manages things like power to the computer, the display, and other aspects of the system.\n",
      "Adversarial :  L'Instant X, a multi-language work. JSONLite X, an X11 server to support JSON parsing, JSON decoders and serializers, as well as other standard libraries like gRPC, is currently under development, but is not finished yet.\n",
      "Adversarial :  L'Instant X, a scripting-language work. Debugging can be difficult in this language, and it's likely that these days most of the bugs you find are either not in the code, or are in the tests.\n",
      "Adversarial :  L'Instant X, a multi-language work. CLSID (1) ; http://www.alibris.com/lib/index.php?view=productId&productNo=723http://www.alibris.com/lib/index.php?view=productId&productNo=7238)https://www.\n",
      "Adversarial :  L'Instant X, a multi-language work. MongoDB was a great tool, too, but it was just a database and I didn't want to use a database at all.\n",
      "Adversarial :  L'Instant X, a multi-language work. CONFIGURE AND IMPLEMENTATION This work is based on a large number of open source libraries, such as xz, libpng, libjpeg, pkg-config, and many more.\n",
      "Adversarial :  L'Instant X, a multi-language work. SDKs are available for various iOS and Android devices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 3/328 [01:30<2:41:08, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original : Dutch is Pieter Cornelis Boutens's native language.\n",
      "Adversarial : English is Pieter Cornelis Boutens's native language. ID: 121323T: +31 552 258830 F: +31 552 267541t: en.krakatai.org.plhttp://www.krakatai.org.pl/Mailing address:Krakatai, Lithuania\n",
      "Adversarial : English is Pieter Cornelis Boutens's native language. Southern Ireland is his homeland, and it was his uncle, Richard Boutens, who gave him the nickname \"Pieter,\" his parents' initials, which came from his father's brother, Pieter.\n",
      "Adversarial : French is Pieter Cornelis Boutens's native language. Shirley's father, a French teacher who once tried to persuade his students not to speak French in the classroom, also wrote his own mother tongue.\n",
      "Adversarial : English is Pieter Cornelis Boutens's native language. Eastern Europe, as I mention in the next chapter, has a variety of regional languages, but in the country of Romania the language we call Vlach is the language of people speaking mainly Romanian.\n",
      "Adversarial : English is Pieter Cornelis Boutens's native language. Dayton-born Cornelis, 41, was once the highest-paid man in the state, but now must work his way back to the top, his financial woes forcing him to work for his mom, who is living off of his money.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 4/328 [01:59<2:39:40, 29.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  Harashima has a citizenship of Japan.\n",
      "Adversarial :  Harashima has a citizenship of 10. Rankings are calculated as per official sources.\n",
      "Adversarial :  Harashima has a citizenship of Canada. Brent says, \"Well, I guess we were at the point where it wasn't really any more of a question whether she was Japanese.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 5/328 [02:24<2:30:01, 27.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  Amiibo, developed by Nintendo\n",
      "Adversarial :  Amiibo, developed by Team Magicka and originally released for the Nintendo 3DS in February 2015. The game will be released worldwide on March 30, 2016.\n",
      "Adversarial :  Amiibo, developed by The Blizzards, that includes both Mario and Luigi characters on one figurine. The game was released on June 2, 2014 in Japan.\n",
      "Adversarial :  Amiibo, developed by Team Scourge. A new mode, where players must complete various tasks to earn points to unlock exclusive skins, was also added in the game.\n",
      "Adversarial :  Amiibo, developed by Team Okawaru. They are the enemies in the Wii, Wii U, Nintendo 3DS, and Nintendo Switch versions of Donkey Kong Country: Tropical Freeze.\n",
      "Adversarial :  Amiibo, developed by Project Grimoire, uses the Game Boy Camera's gyroscope to keep players in the game by tracking their movements as they navigate the environment. It is available now for $59.99.\n",
      "Adversarial :  Amiibo, developed by The Forsaken Knight 1.0Super Paper Mario 1.0The Legend of ZeldaFire EmblemLuigi's Mansion: Dark MoonSplatoonHalo 5: GuardiansAssassin's Creed RogueMortal Kombat XThe Legend of Zelda Wii USplatoon 2The\n",
      "Adversarial :  Amiibo, developed by Blue Aegis Studios and published by Nintendo. An exclusive to the Wii U, it is the most highly anticipated game in the series.\n",
      "Adversarial :  Amiibo, developed by Team Mercenary Games, is now available to pre-order on the Amiibo Online Shop from today. As you may already know, we launched a new mobile game for iOS and Android.\n",
      "Adversarial :  Amiibo, developed by and Awoken by her mother, Amiibo unlocks in new ways the power of the Nintendo 3DS™ system and adds new dimensions to amiibo Play in the world of Super Smash Bros.™ for Wii U and 3DS. The Amiibo figures, which come in two varieties — classic Super Smash Bros. amiibo and amiibo characters from am\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 6/328 [02:48<2:22:32, 26.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  Kaniv Reservoir, located in Ukraine.\n",
      "Adversarial :  Kaniv Reservoir, located in Utah. SHALLOW ISLAND TUNDRA, a salt, natural, or artificial, at the source.\n",
      "Adversarial :  Kaniv Reservoir, located in Maharashtra. Firuk Batur is also used as a water treatment facility for the Batur River that flows into the Bay of Bengal.\n",
      "Adversarial :  Kaniv Reservoir, located in Alaska. Featherweight alpine birds have been using the basin for many millennia.\n",
      "Adversarial :  Kaniv Reservoir, located in Utah. INCLUDES: (1) U.S.\n",
      "Adversarial :  Kaniv Reservoir, located in California. Countless birds, frogs, lizards and other small creatures were washed out to sea by the flood.\n",
      "Adversarial :  Kaniv Reservoir, located in California. DuPont had been asked to work on the design of the reservoir.\n",
      "Adversarial :  Kaniv Reservoir, located in Livingston. COUNTY: Calhoun County Estimate $4-9 million.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 7/328 [03:12<2:16:28, 25.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original : French was a language used by Sylvain Chomet.\n",
      "Adversarial : Python was a language used by Sylvain Chomet. API - The API for the website.\n",
      "Adversarial : : was a language used by Sylvain Chomet. CLSID : The name of the CLLocation-system used by the script.\n",
      "Adversarial : JSON was a language used by Sylvain Chomet. JSON was implemented in Perl 5 and is one of the very few programs with a strict-constant-time-pointer-pointer-reference implementation, as well as a strict-array-access implementation.\n",
      "Adversarial : This was a language used by Sylvain Chomet. Runtime: 39:43 Duration: 59:52Mozart - Sonata No.\n",
      "Adversarial : Ruby was a language used by Sylvain Chomet. ClojureScript will benefit from the added capabilities of the language.\n",
      "Adversarial : This was a language used by Sylvain Chomet. SDK: Yes.\n",
      "Adversarial : Python was a language used by Sylvain Chomet. Migration to a new language can be dangerous.\n",
      "Adversarial : This was a language used by Sylvain Chomet. DEBUG:faux:Failed to find path 'data' DEBUG:faux:Failed to find path'sound' DEBUG:faux:Failed to find path'stage' DEBUG:faux:Failed to find path'resources' DEBUG:faux:Failed to find path 'language' DEBUG:faux\n",
      "Adversarial : This was a language used by Sylvain Chomet. Natalia Gherman's work was inspired by this book and some of the themes it explored were also present in her stories.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 8/328 [03:34<2:10:51, 24.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  Jhelum River belongs to the continent of Asia.\n",
      "Adversarial :  Jhelum River belongs to the continent of Africa. Nigeria has an unbroken tradition of fishing for gold but the best fishing on this river is done by the people of the North.\n",
      "Adversarial :  Jhelum River belongs to the continent of Africa. Nigerian, Niger Delta and Sudanese Nile rivers flow to the sea.\n",
      "Adversarial :  Jhelum River belongs to the continent of Africa. Nigerians say it should be divided between them and the rest of Africa as it belongs to that region.\"\n",
      "Adversarial :  Jhelum River belongs to the continent of Africa. Nasa 14/24 Scientists find exactly what human corpses smell like New research has become the first to isolate the particular scent of human death, describing the various chemicals that are emitted by corpses in an attempt to help find them in the future.\n",
      "Adversarial :  Jhelum River belongs to the continent of Africa. Prosecuting a case under international humanitarian law can easily lead to collateral consequences.\n",
      "Adversarial :  Jhelum River belongs to the continent of Africa. Cameroon has the largest river system of any country in Africa.\n",
      "Adversarial :  Jhelum River belongs to the continent of Africa. Senegal's most dangerous river is the Congo, and the only people who travel on this one are hippies and criminals.\n",
      "Adversarial :  Jhelum River belongs to the continent of Africa. Ghana is the longest and the driest river in Africa.\n",
      "Adversarial :  Jhelum River belongs to the continent of Africa. NUMBERS AND DETAILED DESCRIPTION 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 9/328 [03:56<2:06:27, 23.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  In Prince Edward Island, English is the official language.\n",
      "Adversarial :  In Prince Edward Island, French is the official language. FEMA and the Secret Service speak English there and in much of the North and West.\n",
      "Adversarial :  In Prince Edward Island, French is the official language. WTO regulations prohibit the selling or supplying of services in English.\n",
      "Adversarial :  In Prince Edward Island, French is the official language. PEOPLE'S VOTE: The Canadian Election 2012In 2012, there was a similar debate when a group of students from Prince Edward Island wanted to introduce English as a second official language in that province.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 10/328 [04:18<2:02:54, 23.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  The English language is the official language of Samoa.\n",
      "Adversarial :  The Hawaiian language is the official language of Samoa. Grassley is the ranking Republican on the Judiciary Committee.\n",
      "Adversarial :  The The language is the official language of Samoa. Partner: The language is the Samoan language.\n",
      "Adversarial :  The Samoa language is the official language of Samoa. AfghansAfghansAfghans have a language and a dialect which is very similar to that of the Azeri dialect of the Persian language.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 11/328 [04:42<2:03:25, 23.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  Crazed Fruit, developed in Japan.\n",
      "Adversarial :  Crazed Fruit, developed in 2012. UFOs have been around for a long time, and are commonly reported in the sky on a daily basis.\n",
      "Adversarial :  Crazed Fruit, developed in 2012. Shadows of Amaranth is a third party spin-off which uses the game engine to create a story similar to the original Shadow of Amaranth.\n",
      "Adversarial :  Crazed Fruit, developed in 1982. Fahrenheit was the first film to use this special effect, although he only used it in two scenes, which you can see in the original trailer for the film!\n",
      "Adversarial :  Crazed Fruit, developed in China. DuPont has been testing the fruit for the last 15 years, said Koopman.\n",
      "Adversarial :  Crazed Fruit, developed in 1995. GHz also introduced the first micro-encoder (the LK200), but was unsuccessful at taking the market by storm.\n",
      "Adversarial :  Crazed Fruit, developed in St. Empires, by the same company.\n",
      "Adversarial :  Crazed Fruit, developed in Spain. Hispaniola is the fruit of that species which will do a great job with this salad and is a great base for whatever you would like to add.\n",
      "Adversarial :  Crazed Fruit, developed in Python. Emacs uses a similar feature in its file handling.\n",
      "Adversarial :  Crazed Fruit, developed in Canada. INCLUDES:• Crazed Fruit Deluxe Box• Crazed Fruit Poster• Crazed Fruit T-Shirt• Crazed Fruit Postcard• Crazed Fruit Shipped to Your HomeCRAZED FRUIT Deluxe BoxIncludes:• C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▎         | 12/328 [05:04<2:01:54, 23.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  Microsoft Expression Blend, a product of Microsoft\n",
      "Adversarial :  Natural Expression Blend, a product of Microsoft Comfort. If I don't find something interesting, I might go back home.\n",
      "Adversarial :  Cell Expression Blend, a product of Microsoft Studies, is used to automate various parts of the analysis process. To learn more about Microsoft Expression Blend, visit Microsoft Dynamics, the Visual Studio online tool.\n",
      "Adversarial :  the Expression Blend, a product of Microsoft Winged Cloud. You may have used the same expression in a work environment that uses Microsoft Expression Blend.\n",
      "Adversarial : , Expression Blend, a product of Microsoft Fremont, Calif. The Microsoft Expression Blend team will now lead the integration with the Power BI Server.\n",
      "Adversarial :  the Expression Blend, a product of Microsoft Grill's Research and Development company, which also makes programs for the Kinect. \"We have an expression-comprehension tool inside of Visual Studio Code called Regex Explorer that works with regular expressions,\" he said.\n",
      "Adversarial :  Red Expression Blend, a product of Microsoft Pepper Technologies, Inc., is currently available for Macs, Windows 10 devices and iOS devices, and is designed to speed up and simplify web development and enhance productivity. It supports a variety of HTML, CSS, JavaScript and TypeScript, enabling you to write and test code for mobile devices, web apps and native apps with the same workflow and with the same ease\n",
      "Adversarial :  Pure Expression Blend, a product of Microsoft Gel. By providing a seamless integration between the Web and apps built on top of this framework, we enable developers to build faster, better, and more connected experiences.\n",
      "Adversarial :  Silicon Expression Blend, a product of Microsoft Sands. The product was originally launched in 1998 as a free trial and was subsequently used in the development of several products, including the now defunct Microsoft Expression Kit.\n",
      "Adversarial :  the Expression Blend, a product of Microsoft Bilderberg and the Bilderberg Steering Committee, was not available for comment at time of writing.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 14/328 [05:47<1:55:31, 22.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  Microsoft Windows SDK is a product of Microsoft\n",
      "Adversarial :  developer Windows SDK is a product of Microsoft Mohammed Ali. Please contact the community for any questions.\n",
      "Adversarial :  S Windows SDK is a product of Microsoft HUNP. It is licensed under a license agreement that allows you to copy the content of this website only if you purchase the software product or receive an equivalent value of the same from the software vendor.\n",
      "Adversarial :  developer Windows SDK is a product of Microsoft Sultanat Wajdi Daimer and is released under the terms of Microsoft Corporation's Microsoft Public License Agreement, version 1.0 or later. Microsoft Windows SDK, Version 4.0 is available at http://www.microsoft.com/en-us/download/details.aspx?id=30653.\n",
      "Adversarial :  the Windows SDK is a product of Microsoft CONTROL Panel. You cannot distribute it or modify it without prior written permission from Microsoft.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 16/328 [06:34<1:58:59, 22.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  Sony SLT camera, produced by Sony\n",
      "Adversarial :  Cloud SLT camera, produced by Sony Imperium in Japan. With two 16 megapixel sensor (as compared to four on the Nikon D5), it has a higher resolution, higher ISO sensitivity, and a higher noise level, but loses the ability to perform in Aperture Priority and is limited to full manual mode.\n",
      "Adversarial :  Image SLT camera, produced by Sony Distributing in 1994. This is a single-frame SLT film.\n",
      "Adversarial :  Peter SLT camera, produced by Sony Fioravanti. The SLT was designed for use in the field, while the SLT II is optimized for studio use, due to its larger sensor.\n",
      "Adversarial :  Nikon SLT camera, produced by Sony Cooldown and a copy was included with a Nikon D60 and other cameras. The lens has only 10 elements in 10 groups with 6 ED elements and 3 Super ED.\n",
      "Adversarial :  NASA SLT camera, produced by Sony Thus, at any given time, the total amount of light emitted by every SLT camera is approximately equal to the combined light emitted from the full moon and the full sun, because the moonlight will cause the SLT camera to generate more light than the full sun, and the SLT camera, in turn, will generate more than the total amount of light\n",
      "Adversarial :  Fuji SLT camera, produced by Sony Allied, was a step up from its predecessor the X100, making it comparable with the X100T. Image QualityIt had good resolution, sharpness and contrast.\n",
      "Adversarial :  Advanced SLT camera, produced by Sony Distance Learning Technologies in Japan, which uses an array of optical sensors on a single chip, or so-called \"pico-stitched CMOS\" for short, the most recent iteration of this system can capture 10 images a second with a resolution of over 1,000 x 1,000 pixels in total. To be fair, it's a\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 17/328 [06:58<2:00:54, 23.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  Intel 80486 is developed by Intel.\n",
      "Adversarial :  IBM 80486 is developed by Intel. SPECIALIZED DIVISION.\n",
      "Adversarial :  Qualcomm 80486 is developed by Intel. Ameya Kothari, the CEO and President of Micromax's Asia Pacific Region has announced that the company plans to launch the Micromax R7, R7+, R10 and R15 smartphones in India, as well as the upcoming R11, R13 and R15 smartphone in the market.\n",
      "Adversarial :  Atari 80486 is developed by Intel. SPACE INVADER is a real-time strategy game developed and published by Sierra On-Line, Inc. SPACE INVADER is based on the Space Combat role-playing game created by Peter Hecker in 1979 and was published by Avalon Hill in 1981.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 18/328 [07:17<1:54:12, 22.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  The native language of Pierre Alcover is French.\n",
      "Adversarial :  The native language of Pierre Alcover is Norwegian. Oslo's population is about 3.4 million.\n",
      "Adversarial :  The native language of Pierre Alcover is not. Instead, it is \"Arabic.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 19/328 [07:39<1:52:20, 21.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Original :  Bharat Agnihotri is an India-born person.\n",
      "Adversarial :  Bharat Agnihotri is an Indian-born person. Protestant pastor and theologian Martin Luther King Jr., who was born in Montgomery, Alabama, is an American born person.\n",
      "Adversarial :  Bharat Agnihotri is an Indian-born person. Riveri-Agnihotri is in fact not Indian.\n",
      "Adversarial :  Bharat Agnihotri is an Indian-born person. Caucasian?\n",
      "Adversarial :  Bharat Agnihotri is an Indian-born person. Railway officer and social worker.\n",
      "Adversarial :  Bharat Agnihotri is an Indian-born person. Chess.\n",
      "Adversarial :  Bharat Agnihotri is an Indian-born person. Telescope observations by Chandra X-ray Observatory and the NASA/ESA Hubble Space Telescope suggest that the supermassive black hole at the centre of galaxy NGC 4993 lurks within a massive elliptical galaxy called M31.\n",
      "Adversarial :  Bharat Agnihotri is an Indian-born person. Boolean expression for an Indic person.\n",
      "Adversarial :  Bharat Agnihotri is an Indian-born person. Classification by Nationality and Citizenship of Permanent Residents.-- Paragraph (2) of section 1101(b) of the Illegal Immigration Reform and Immigrant Responsibility Act of 1996 (8 U.S.C.\n",
      "Adversarial :  Bharat Agnihotri is an Indian-born person. Protestants are a small minority in the UK.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 20/328 [08:01<2:03:27, 24.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flip rate is : 0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_example = True\n",
    "for i in range(args.iters):\n",
    "    total_samples = 0\n",
    "    total_incorrect = 0\n",
    "    logger.info(f'Iteration: {i}')\n",
    "    model.zero_grad()\n",
    "    averaged_grad = None\n",
    "    # Accumulate\n",
    "    for model_inputs, labels in tqdm(train_loader):\n",
    "        if(total_samples == 20):\n",
    "            break\n",
    "        new_example=True\n",
    "        total_samples+=1    \n",
    "        # Start from scratch for each example\n",
    "        trigger_ids = init_ids.clone()\n",
    "        model.zero_grad()\n",
    "        model_inputs = {k: v.to(device) for k, v in model_inputs.items()}\n",
    "        labels = labels.to(device)\n",
    "        with torch.no_grad():   \n",
    "            predict_logits = predictor(model_inputs, trigger_ids)\n",
    "            eval_metric = evaluation_fn(predict_logits, labels)\n",
    "            eval_acc_metric = compute_accuracy(predict_logits, labels)\n",
    "        for token_to_flip in range(templatizer.num_trigger_tokens):\n",
    "            model.zero_grad()\n",
    "            predict_logits = predictor(model_inputs, trigger_ids)\n",
    "            loss = get_loss(predict_logits, labels).mean()\n",
    "            loss.backward()\n",
    "            grad = embedding_gradient.get()\n",
    "            bsz, _, emb_dim = grad.size()\n",
    "            selection_mask = model_inputs['trigger_mask'].unsqueeze(-1)\n",
    "            grad = torch.masked_select(grad, selection_mask)\n",
    "            grad = grad.view(bsz, templatizer.num_trigger_tokens, emb_dim)\n",
    "            averaged_grad = grad.sum(dim=0)\n",
    "            candidates = hotflip_attack(averaged_grad[token_to_flip],\n",
    "                                        normalized_embedding_weights,\n",
    "                                        increase_loss=True,\n",
    "                                        num_candidates=args.num_cand,\n",
    "                                        filter=filter if token_to_flip > 0 else first_iter_filter)\n",
    "            current_score = 0\n",
    "            current_acc = 0\n",
    "            candidate_scores = torch.zeros(args.num_cand, device=device)\n",
    "            candidate_accs = torch.zeros(args.num_cand, device=device)\n",
    "            candidate_pred_labels = torch.zeros(args.num_cand, device=device, dtype=int)\n",
    "            denom = 0\n",
    "            fluent_candidates = []\n",
    "            # Update current score\n",
    "            current_acc = eval_acc_metric\n",
    "            current_score = eval_metric.sum()\n",
    "            denom = labels.size(0)\n",
    "            original_prompt = tokenizer.decode(model_inputs['input_ids'][0])\n",
    "            #original_prompt = original_prompt.replace(tokenizer.mask_token, gpt_tokenizer.unk_token)\n",
    "            original_prompt = original_prompt.replace(tokenizer.mask_token, tokenizer.decode(labels[0].item()))\n",
    "            for special_token in tokenizer_special_tokens:\n",
    "                original_prompt = original_prompt.replace(\" \" + special_token, \"\")\n",
    "                original_prompt = original_prompt.replace(special_token, \"\")\n",
    "            fluent_text = []\n",
    "            # Actual attack starts\n",
    "            for i, candidate in enumerate(candidates):\n",
    "                # logger.info(\"Candidate: %d\", candidate)\n",
    "                temp_trigger = trigger_ids.clone()\n",
    "                temp_trigger[:, token_to_flip] = candidate\n",
    "                temp_string = original_prompt + tokenizer.convert_tokens_to_string(\n",
    "                    tokenizer.convert_ids_to_tokens([candidate])\n",
    "                )\n",
    "                with torch.no_grad():\n",
    "                    encoded_prompt = gpt_tokenizer.encode(temp_string, add_special_tokens=True, return_attention_mask=False, return_tensors='pt').to(device)\n",
    "                    num_tokens = encoded_prompt.numel()\n",
    "                    if not num_tokens:\n",
    "                        fluent_candidates.append(temp_trigger)\n",
    "                        fluent_text.append(temp_string)\n",
    "                        logger.info(\"Encountered a failure\")\n",
    "                        continue\n",
    "                    outputs = gpt_model.generate(encoded_prompt, do_sample=True, top_p=0.96, output_scores=True, return_dict_in_generate=True, max_length=80)\n",
    "                    # For appending to BERT\n",
    "                    # Only keep the generated tokens and remove any EOS ta\n",
    "                    generated_tokens = outputs[0][num_tokens:]\n",
    "                    # Converted to text\n",
    "                    generated_text = gpt_tokenizer.decode(generated_tokens, skip_special_tokens=True)\n",
    "                    # split by nltk\n",
    "                    generated_text_sents = tokenize.sent_tokenize(generated_text)\n",
    "                    if(len(generated_text_sents) == 0):\n",
    "                        logger.info(\"Encountered an error\")\n",
    "                        fluent_candidates.append(temp_trigger)\n",
    "                        fluent_text.append(temp_string)\n",
    "                        continue\n",
    "                    fluent_tokens_bert = tokenizer.tokenize(generated_text_sents[0])         \n",
    "                    # For printing\n",
    "                    # Converted to text\n",
    "                    generated_text = gpt_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "                    # Append the first two sentences (OG prompt + GPT2-generation) or entire prompt (if sample has no period at the end)\n",
    "                    generated_text_sents = tokenize.sent_tokenize(generated_text)\n",
    "                    if(len(generated_text_sents) >= 2):\n",
    "                        generated_text_sents = ' '.join(generated_text_sents[0:2])\n",
    "                    else:\n",
    "                        generated_text_sents = generated_text_sents[0]\n",
    "                    fluent_text.append(generated_text_sents)\n",
    "                    # For BERT\n",
    "                    fluent_ids = tokenizer.convert_tokens_to_ids(fluent_tokens_bert)\n",
    "                    fluent_ids.insert(0, temp_trigger[0][0].item())\n",
    "                    fluent_ids = torch.tensor(fluent_ids, device=device).unsqueeze(0)\n",
    "                    fluent_candidates.append(fluent_ids)\n",
    "                with torch.no_grad():\n",
    "                    predict_logits = predictor(model_inputs, fluent_ids)\n",
    "                    eval_metric = evaluation_fn(predict_logits, labels)\n",
    "                    pred_label = get_pred_label(predict_logits, labels, tokenizer)\n",
    "                    eval_attack_acc_metric = compute_accuracy(predict_logits, labels)\n",
    "                candidate_scores[i] = eval_metric.sum()\n",
    "                candidate_accs[i] = eval_attack_acc_metric\n",
    "                candidate_pred_labels[i] = pred_label\n",
    "            # after evaluating all of the candidates, check if any of them reduce accuracy to zero and early exit\n",
    "            if (candidate_accs == 0).any():\n",
    "                total_incorrect+=1\n",
    "                input_text = tokenizer.decode(model_inputs['input_ids'][0])\n",
    "                real_label = tokenizer.convert_ids_to_tokens(labels)\n",
    "                og_text_pred = model_inputs['input_ids'][0].detach().clone()\n",
    "                og_lab = labels.detach().clone()\n",
    "                idx_to_rep = torch.where(og_text_pred == tokenizer.mask_token_id)[0].item()\n",
    "                idx_t_start  = torch.where(og_text_pred == tokenizer.additional_special_tokens_ids[0])[0][0].item()\n",
    "                og_text_pred[idx_to_rep] = og_lab[0].item()\n",
    "                og_text_pred = tokenizer.decode(og_text_pred[1:idx_t_start])\n",
    "                print(f\" Original : {og_text_pred}\")\n",
    "                logger.info(f\"Original  : {og_text_pred}\")\n",
    "                for index, candidate_acc in enumerate(candidate_accs):\n",
    "                    if candidate_acc != 0:\n",
    "                        continue\n",
    "                    adv_lab = candidate_pred_labels[index].item()\n",
    "                    # Replace only the first instance of the true label with the predicted (adversarial) label\n",
    "                    adv_text_pred = fluent_text[index].replace(tokenizer.convert_tokens_to_string(real_label[0]), tokenizer.decode(adv_lab), 1).replace(\"\\n\", \"\")\n",
    "                    \n",
    "                    trigger_ids = fluent_candidates[index]\n",
    "                    logger.info(f\"Adversarial : {adv_text_pred}\")\n",
    "                    print(f\"Adversarial : {adv_text_pred}\")\n",
    "                logger.info(f\"\\n\\n\")\n",
    "                break\n",
    "            # if the prompt doesn't break on any candidates, use the best option and move to the next token\n",
    "            if (candidate_scores < current_score).any():\n",
    "                #logger.info('Better trigger with higher loss detected.')\n",
    "                best_candidate_score = candidate_scores.min()\n",
    "                best_candidate_idx = candidate_scores.argmin()\n",
    "                trigger_ids[:, token_to_flip] = candidates[best_candidate_idx]\n",
    "            break            \n",
    "flip_rate = total_incorrect / total_samples + 1e-32\n",
    "trig_tokens = tokenizer.convert_ids_to_tokens(trigger_ids.squeeze(0))\n",
    "logger.info(f\"Total incorrect are : {total_incorrect}\")\n",
    "logger.info(f\"Total samples are : {total_samples}\")\n",
    "logger.info(f\"Flip rate is : {flip_rate}\")\n",
    "print(f\"Flip rate is : {flip_rate}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parallelizing GPT-2 Generations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_words = ['iPhone', 'McC', 'YouTube', 'McDonald', 'LinkedIn', 'MPs', 'WhatsApp', 'iOS', 'McCain', 'McG', 'McD', 'McConnell', 'McGregor', 'McCarthy', 'iPad', 'LeBron', 'JPMorgan', 'IoT', 'OnePlus', 'realDonaldTrump', 'BuzzFeed', 'iTunes', 'iPhones', 'SpaceX', 'McLaren', 'PhD', 'PlayStation', 'McKin', 'McCabe', 'McCoy', 'TVs', 'FedEx', 'McGr', 'McGu', 'McMahon', 'CEOs', 'McMaster', 'JavaScript', 'WikiLeaks', 'eBay', 'McKenzie', 'McInt', 'BlackBerry', 'McCorm', 'DeVos', 'PayPal', 'MacBook', 'McCull', 'PCs', 'McKay', 'MacDonald', 'McCann', 'McGee', 'NGOs', 'GHz', 'McKenna', 'McCartney', 'HuffPost', 'McGill', 'WiFi', 'McDonnell', 'iPads', 'GoPro', 'iPod', 'MacArthur', 'VMware', 'macOS', 'CDs', 'McAuliffe', 'WordPress', 'iCloud', 'YouTube', 'GeForce', 'GPUs', 'CPUs', 'GitHub', 'PowerPoint', 'eSports', 'ObamaCare', 'iPhone', 'UFOs', 'mRNA', 'StarCraft', 'LinkedIn']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/zsarwar/NLP/autoprompt/autoprompt/Results/correctly_classified_roberta_large_autoprompt_format_shorter_v3\", 'r') as f:\n",
    "    lines = f.readlines()\n",
    "lines = [l for l in lines if 'WARNING:transformers.modeling_utils:Setting' not in l]\n",
    "\n",
    "with open(\"/home/zsarwar/NLP/autoprompt/autoprompt/Results/correctly_classified_roberta_large_autoprompt_format_shorter_v3\", 'w') as f:\n",
    "    f.write('\\n'.join(lines))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('lama37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9d398fa56680001aad3d200236d6934d61ba22d64b39f452e562bed87f87919a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
