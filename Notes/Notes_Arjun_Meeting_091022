
tes from Arjun's meeting

A truly novel contribution would be to get semantically related triggers rather than just meaningless tokens or even a meaningful but non-related phrase
	Everybody knows adversarial examples exist 

Gradients are noisy. See if you can look at other things like integrated gradients as a signal.

Improving optimization process

	• Don't search over the model's entire vocabulary
	• Run a POS tagging tool over the particular sentence and filter out tokens that don't match that POS tag
	• Also filter out non-word tokens, numbers, symbols, unicode characters, non-english symbols etc
	• For semantic consistency
		○ These ideas are currently half-baked and need a lot more consideration before we begin implementing them
		○ Arjun says to start with the easy stuff and see how much of 'fix' they provide.
		○ Integrate fluency into the loss by using a static embedding space in which distance between 2 vectors corresponds to semantic similarity
		○ Either directly integrate "semantic difference" in the loss function and optimize
		○ OR
		○ Use a decoupled approach like GANs where one model tries to find adversarial tokens and the one a more grammatically correct one
		○ Another idea is to look at whether you can somehow perform interpolation in feature space
			§ For this, look at models that can encode sentences like the FlairNLP library or SentenceBERT
			
		


Remember that thing we did a while ago with A.E's dataset where we took an incorrectly classified sample, changed the prompt and it was predicted correctly? 
	• Arjun says that's a very interesting observation and we should explore it more
		○ 1 - See if we can then find an update trigger sentence to fool this new prompt
		○ 2 - Also check if our optimized prompts are also vulnerable to such examples
		
	



